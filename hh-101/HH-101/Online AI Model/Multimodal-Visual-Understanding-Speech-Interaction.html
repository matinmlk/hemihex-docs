<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-hh101 docs-version-current docs-doc-page docs-doc-id-HH-101/Online AI Model/Multimodal-Visual-Understanding-Speech-Interaction" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Multimodal visual understand speech interaction | HemiHex Docs</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://docs.hemihex.com/img/logo.png"><meta data-rh="true" name="twitter:image" content="https://docs.hemihex.com/img/logo.png"><meta data-rh="true" property="og:url" content="https://docs.hemihex.com/hh-101/HH-101/Online AI Model/Multimodal-Visual-Understanding-Speech-Interaction"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-hh101-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-hh101-current"><meta data-rh="true" property="og:title" content="Multimodal visual understand speech interaction | HemiHex Docs"><meta data-rh="true" name="description" content="1. Concept Introduction"><meta data-rh="true" property="og:description" content="1. Concept Introduction"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://docs.hemihex.com/hh-101/HH-101/Online AI Model/Multimodal-Visual-Understanding-Speech-Interaction"><link data-rh="true" rel="alternate" href="https://docs.hemihex.com/hh-101/HH-101/Online AI Model/Multimodal-Visual-Understanding-Speech-Interaction" hreflang="en"><link data-rh="true" rel="alternate" href="https://docs.hemihex.com/hh-101/HH-101/Online AI Model/Multimodal-Visual-Understanding-Speech-Interaction" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Multimodal visual understand speech interaction","item":"https://docs.hemihex.com/hh-101/HH-101/Online AI Model/Multimodal-Visual-Understanding-Speech-Interaction"}]}</script><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="HemiHex Docs RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="HemiHex Docs Atom Feed"><link rel="stylesheet" href="/assets/css/styles.6c03f6b7.css">
<script src="/assets/js/runtime~main.a828d60c.js" defer="defer"></script>
<script src="/assets/js/main.55e05dad.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/logo.png"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/docs/intro"><div class="navbar__logo"><img src="/img/logo.png" alt="HemiHex" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.png" alt="HemiHex" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/hh-101/HH-101/Board Basics Tasks/Jetson-board-introduction">HH-101</a><a class="navbar__item navbar__link" href="/hh-bot/intro">HH-Bot</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/hh-101/HH-101/Board Basics Tasks/Jetson-board-introduction"><span title="Board Basics Tasks" class="categoryLinkLabel_W154">Board Basics Tasks</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/hh-101/HH-101/Linux Basics/linux-basics"><span title="Linux Basics" class="categoryLinkLabel_W154">Linux Basics</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/hh-101/HH-101/GPIO control course/gpio-description-04-gpiocontrolcourse-4-1"><span title="GPIO control course" class="categoryLinkLabel_W154">GPIO control course</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/hh-101/HH-101/Vision Basic Course/csi-camera-preview-05-visionbasiccourse-5-1"><span title="Vision Basic Course" class="categoryLinkLabel_W154">Vision Basic Course</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/hh-101/HH-101/OpenCV/opencv-image-reading"><span title="OpenCV" class="categoryLinkLabel_W154">OpenCV</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/hh-101/HH-101/Advanced Vision/1-1-tensorflow-on-jetson"><span title="Advanced Vision" class="categoryLinkLabel_W154">Advanced Vision</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/hh-101/HH-101/Docker/docker-introduction"><span title="Docker" class="categoryLinkLabel_W154">Docker</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/hh-101/HH-101/ROS1/ros-introduction-core"><span title="ROS1" class="categoryLinkLabel_W154">ROS1</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/hh-101/HH-101/ROS2/ros2-service"><span title="ROS2" class="categoryLinkLabel_W154">ROS2</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/hh-101/HH-101/Offline AI Model/ollama-11-offlineaimodel-11-1"><span title="Offline AI Model" class="categoryLinkLabel_W154">Offline AI Model</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/hh-101/HH-101/Online AI Model/multimodal-visual-understanding-application-12-onlineaimodel-12-2"><span title="Online AI Model" class="categoryLinkLabel_W154">Online AI Model</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/hh-101/HH-101/Online AI Model/multimodal-visual-understanding-application-12-onlineaimodel-12-2"><span title="Multimodal Video Understanding" class="linkLabel_WmDU">Multimodal Video Understanding</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/hh-101/HH-101/Online AI Model/openrouter-api-aggregation-platform-12-onlineaimodel-12-1"><span title="OpenRouter Large Model API Aggregation Platform" class="linkLabel_WmDU">OpenRouter Large Model API Aggregation Platform</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/hh-101/HH-101/Online AI Model/Multimodal-Visual-Localization-Application"><span title="Multimodal visual localization application" class="linkLabel_WmDU">Multimodal visual localization application</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/hh-101/HH-101/Online AI Model/Multimodal-Table-Scanning-Application"><span title="Multimodal table scanning application" class="linkLabel_WmDU">Multimodal table scanning application</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/hh-101/HH-101/Online AI Model/Multimodal-Autonomous-Proxy-Application"><span title="Multimodal autonomous proxy application" class="linkLabel_WmDU">Multimodal autonomous proxy application</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/hh-101/HH-101/Online AI Model/Voice-Interaction-Hardware-Connection"><span title="Voice Interaction Hardware Connection" class="linkLabel_WmDU">Voice Interaction Hardware Connection</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/hh-101/HH-101/Online AI Model/AI-Large-Model-Voice-Interaction"><span title="AI large model voice interaction" class="linkLabel_WmDU">AI large model voice interaction</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/hh-101/HH-101/Online AI Model/Multimodal-Visual-Understanding-Speech-Interaction"><span title="Multimodal visual understand speech interaction" class="linkLabel_WmDU">Multimodal visual understand speech interaction</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/hh-101/HH-101/Online AI Model/Multi-Module-Visual-Position-Application"><span title="Multi module visual position application" class="linkLabel_WmDU">Multi module visual position application</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/hh-101/HH-101/Online AI Model/Multimodal-Table-Scanning-Application-v2"><span title="Multimodal table scanning application-10" class="linkLabel_WmDU">Multimodal table scanning application-10</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/hh-101/HH-101/Online AI Model/Multimodal-Autonomous-Proxy-Application-v2"><span title="Multimodal autonomous proxy application-11" class="linkLabel_WmDU">Multimodal autonomous proxy application-11</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/hh-101/HH-101/Online AI Model/Online-Speech-to-Text-ASR"><span title="Online speech to text (ASR)" class="linkLabel_WmDU">Online speech to text (ASR)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/hh-101/HH-101/Online AI Model/AI-Large-Model-Online-Voice-Assistant"><span title="AI large model online voice assistant" class="linkLabel_WmDU">AI large model online voice assistant</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/hh-101/HH-101/NVIDIA Isaac ROS Course/Build-Isaac-ROS-Environment"><span title="NVIDIA Isaac ROS Course" class="categoryLinkLabel_W154">NVIDIA Isaac ROS Course</span></a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Online AI Model</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Multimodal visual understand speech interaction</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Multimodal visual understand speech interaction</h1></header><h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-concept-introduction">1. Concept Introduction<a href="#1-concept-introduction" class="hash-link" aria-label="Direct link to 1. Concept Introduction" title="Direct link to 1. Concept Introduction" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="11-what-is-visual-understanding">1.1 What is &quot;Visual Understanding&quot;?<a href="#11-what-is-visual-understanding" class="hash-link" aria-label="Direct link to 1.1 What is &quot;Visual Understanding&quot;?" title="Direct link to 1.1 What is &quot;Visual Understanding&quot;?" translate="no">​</a></h3>
<p>In the<code>largemodel</code>project, the<strong>multimodal visual understanding</strong>feature enables robots to go beyond simply &quot;seeing&quot; a matrix of pixels and truly &quot;understand&quot; the content, objects, scenes, and relationships within an image. This is like giving robots a pair of thinking eyes.</p>
<p>The core tool for this feature is **seewhat`. When a user issues a command such as &quot;see what&#x27;s here,&quot; the system invokes this tool, triggering a series of background operations that ultimately provide the user with AI-generated analysis of the live image in natural language.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="12-brief-implementation-principle">1.2 Brief Implementation Principle<a href="#12-brief-implementation-principle" class="hash-link" aria-label="Direct link to 1.2 Brief Implementation Principle" title="Direct link to 1.2 Brief Implementation Principle" translate="no">​</a></h3>
<p>The basic principle is to feed two different types of information—<strong>image (visual information)<strong>and</strong>text (linguistic information)</strong>—into a powerful multimodal large model (such as LLaVA).</p>
<ol>
<li class=""><strong>Image Encoding</strong> : The model first uses a visual encoder to convert the input image into a computer-interpretable numerical vector. This vector captures image features such as color, shape, and texture.</li>
<li class=""><strong>Text Encoding</strong> : Simultaneously, the user&#x27;s question (e.g., &quot;What&#x27;s on the table?&quot;) is also converted into a text vector.</li>
<li class=""><strong>Cross-modal Fusion</strong> : The most critical step is to fuse the image and text vectors in a special &quot;attention layer.&quot; Here, the model learns to &quot;focus&quot; on the parts of the image relevant to the question. For example, when asked about the word &quot;table,&quot; the model will pay more attention to areas in the image that match the characteristics of a table.</li>
<li class=""><strong>Answer Generation</strong> : Finally, a large language model (LLM) generates a descriptive text answer based on this fused information.</li>
</ol>
<p>Simply put, this<strong>involves &quot;highlighting&quot; the corresponding parts of the image with words and then describing the &quot;highlighted&quot; parts with words</strong>.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-project-architecture">2. Project Architecture<a href="#2-project-architecture" class="hash-link" aria-label="Direct link to 2. Project Architecture" title="Direct link to 2. Project Architecture" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="key-code">Key Code<a href="#key-code" class="hash-link" aria-label="Direct link to Key Code" title="Direct link to Key Code" translate="no">​</a></h3>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-tool-layer-entry--largemodelutilstools_managerpy-">1. Tool Layer Entry ( largemodel/utils/tools_manager.py )<a href="#1-tool-layer-entry--largemodelutilstools_managerpy-" class="hash-link" aria-label="Direct link to 1. Tool Layer Entry ( largemodel/utils/tools_manager.py )" title="Direct link to 1. Tool Layer Entry ( largemodel/utils/tools_manager.py )" translate="no">​</a></h4>
<p>The<code>seewhat</code>function in this file defines the tool&#x27;s execution flow.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># From largemodel/utils/tools_manager.py</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">class</span><span class="token plain"> </span><span class="token class-name">ToolsManager</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">seewhat</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">Capture camera frame and analyze environment with AI model.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="display:inline-block;color:#e3116c"></span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">:return: Dictionary with scene description and image path, or None if failed.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">node</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">get_logger</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">info</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;Executing seewhat() tool&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">image_path </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">capture_frame</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> image_path</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Use isolated context for image analysis.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">analysis_text </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">_get_actual_scene_description</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">image_path</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Return structured data for the tool chain.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token string" style="color:#e3116c">&quot;description&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> analysis_text</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token string" style="color:#e3116c">&quot;image_path&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> image_path</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">else</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ... (Error handling)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">None</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">_get_actual_scene_description</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> image_path</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> message_context</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">None</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">Get AI-generated scene description for captured image.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="display:inline-block;color:#e3116c"></span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">:param image_path: Path to captured image file.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">:return: Plain text description of scene.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">try</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ... (Build Prompt)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Force use of a plain text system prompt with a clean, one-time context.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">simple_context </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token string" style="color:#e3116c">&quot;role&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;system&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token string" style="color:#e3116c">&quot;content&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;You are an image description assistant. ...&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">result </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">node</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model_client</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">infer_with_image</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">image_path</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> scene_prompt</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> message</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">simple_context</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ... (Processing Result)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> description</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">except</span><span class="token plain"> Exception </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> e</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ...</span><br></span></code></pre></div></div>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-model-interface-layer--largemodelutilslarge_model_interfacepy-">2. Model interface layer ( largemodel/utils/large_model_interface.py )<a href="#2-model-interface-layer--largemodelutilslarge_model_interfacepy-" class="hash-link" aria-label="Direct link to 2. Model interface layer ( largemodel/utils/large_model_interface.py )" title="Direct link to 2. Model interface layer ( largemodel/utils/large_model_interface.py )" translate="no">​</a></h4>
<p>The<code>infer_with_image</code>function in this file is the unified entry point for all image understanding tasks. It is responsible for calling the specific model implementation according to the configuration.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># From largemodel/utils/large_model_interface.py</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">class</span><span class="token plain"> </span><span class="token class-name">model_interface</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">infer_with_image</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> image_path</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> text</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">None</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> message</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">None</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;Unified image inference interface. &quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ... (Prepare message)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">try</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Determine which specific implementation to call based on the value of self.llm_platform</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">llm_platform </span><span class="token operator" style="color:#393A34">==</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;ollama&#x27;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">response_content </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">ollama_infer</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">messages</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> image_path</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">image_path</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">elif</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">llm_platform </span><span class="token operator" style="color:#393A34">==</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;tongyi&#x27;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ... Logic for calling the Tongyi model</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">pass</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ... (Logic for other platforms)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token string" style="color:#e3116c">&#x27;response&#x27;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> response_content</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;messages&#x27;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">messages</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">copy</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">}</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="code-analysis">Code Analysis<a href="#code-analysis" class="hash-link" aria-label="Direct link to Code Analysis" title="Direct link to Code Analysis" translate="no">​</a></h3>
<p>This feature&#x27;s implementation involves two main layers: the tool layer defines the business logic, and the model interface layer is responsible for communicating with the large language model. This layered design is key to achieving platform versatility.</p>
<ol>
<li class=""><strong>Tool Layer (tools_manager.py)</strong>:</li>
</ol>
<ul>
<li class="">The <code>seewhat</code> function is the core business of the visual understanding function. It encapsulates the entire &quot;seeing&quot; action process: first, it calls the <code>capture_frame</code> method to obtain an image, then calls <code>_get_actual_scene_description</code> to prepare a prompt for the model to analyze the image.</li>
<li class="">The most critical step is calling the <code>infer_with_image</code> method of the model interface layer. It does not care about the underlying model; it only passes the two core data elements, &quot;image&quot; and &quot;analysis instructions,&quot; to the model interface layer.</li>
<li class="">Finally, it packages the analysis results (plain text descriptions) received from the model interface layer into a structured dictionary and returns them. This allows upper-layer applications to easily use the analysis results.</li>
</ul>
<ol start="2">
<li class=""><strong>Model Interface Layer (large_model_interface.py):</strong></li>
</ol>
<ul>
<li class="">The <code>infer_with_image</code> function acts as a &quot;dispatching center.&quot; Its primary responsibility is to check the current platform configuration ( <code>self.llm_platform</code> ) and, based on the configuration, dispatch tasks to specific handlers (such as <code>ollama_infer</code> or <code>tongyi_infer</code> ).</li>
<li class="">This layer is key to adapting to different AI platforms. All platform-specific operations (such as data encoding and API call formats) are encapsulated within their respective handlers.</li>
<li class="">In this way, the business logic code in <code>tools_manager.py</code> remains unchanged to support a variety of different large-model backend services. It simply interacts with the unified, stable <code>infer_with_image</code> interface.</li>
</ul>
<p>In summary, the<code>seewhat</code>tool&#x27;s execution flow demonstrates a clear separation of responsibilities:<code>ToolsManager</code>defines the &quot;what&quot; (acquiring an image and requesting analysis), while<code>model_interface</code>defines the &quot;how&quot; (selecting the appropriate model platform based on the current configuration and interacting with it). This makes the tutorial&#x27;s analysis universal; the core code logic remains consistent regardless of whether the user is using the model in online or offline mode. 3. Practical Operations</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="31-configuring-online-llm">3.1 Configuring Online LLM<a href="#31-configuring-online-llm" class="hash-link" aria-label="Direct link to 3.1 Configuring Online LLM" title="Direct link to 3.1 Configuring Online LLM" translate="no">​</a></h2>
<ol>
<li class=""><strong>First, obtain an API key from any of the platforms described in the previous tutorials</strong></li>
<li class=""><strong>Next, update the key in the configuration file. Open the model interface configuration file large_model_interface.yaml</strong>: xxxxxxxxxxvim~/hemihex_ws/src/largemodel/config/large_model_interface.yaml</li>
<li class=""><strong>Enter your API Key</strong>:Find<!-- --> the corresponding section and paste the API Key you just copied. This example uses the Tongyi Qianwen configuration. xxxxxxxxxx# large_model_interface.yaml## Thousand Questions on Tongyiqianwen_api_key:&quot;sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&quot;# Paste your Keyqianwen_model:&quot;qwen-vl-max-latest&quot;# You can choose the model as needed, such as qwen-turbo, qwen-plus</li>
<li class=""><strong>Open the main configuration file HemiHex.yaml</strong>: xxxxxxxxxxvim~/hemihex_ws/src/largemodel/config/HemiHex.yaml</li>
<li class=""><strong>Select the online platform you want to use</strong>:Change<!-- --> the<code>llm_platform</code>parameter to the platform name you want to use. xxxxxxxxxx# HemiHex.yamlmodel_service:ros__parameters:# ...llm_platform:&#x27;tongyi&#x27;#Optional platforms: &#x27;ollama&#x27;, &#x27;tongyi&#x27;, &#x27;spark&#x27;, &#x27;qianfan&#x27;, &#x27;openrouter&#x27;</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="32-launching-and-testing-the-functionality">3.2 Launching and Testing the Functionality<a href="#32-launching-and-testing-the-functionality" class="hash-link" aria-label="Direct link to 3.2 Launching and Testing the Functionality" title="Direct link to 3.2 Launching and Testing the Functionality" translate="no">​</a></h3>
<ol>
<li class=""><strong>Start the largemodel main program</strong>:Open<!-- --> a terminal and run the following command: xxxxxxxxxxros2 launch largemodel largemodel_control.launch.py</li>
<li class=""><strong>Test</strong>:</li>
</ol>
<ul>
<li class=""><strong>Wake up</strong>: Say &quot;Hi,HemiHex&quot; into the microphone.</li>
<li class=""><strong>Talk</strong>: After the speaker responds, you can say, &quot;What do you see?&quot;</li>
<li class=""><strong>Observe the log</strong>: In the terminal running the<code>launch</code>file, you should see the following:<!-- -->
<ol>
<li class="">The ASR node recognizes your question and prints it.</li>
<li class="">The <code>model_service</code> node receives the text, calls the LLM, and prints the LLM&#x27;s response.</li>
</ol>
</li>
<li class=""><strong>Listen for the answer</strong>: After a while, you should hear the answer from the speaker.</li>
</ul></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/hh-101/HH-101/Online AI Model/AI-Large-Model-Voice-Interaction"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">AI large model voice interaction</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/hh-101/HH-101/Online AI Model/Multi-Module-Visual-Position-Application"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Multi module visual position application</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#1-concept-introduction" class="table-of-contents__link toc-highlight">1. Concept Introduction</a><ul><li><a href="#11-what-is-visual-understanding" class="table-of-contents__link toc-highlight">1.1 What is &quot;Visual Understanding&quot;?</a></li><li><a href="#12-brief-implementation-principle" class="table-of-contents__link toc-highlight">1.2 Brief Implementation Principle</a></li></ul></li><li><a href="#2-project-architecture" class="table-of-contents__link toc-highlight">2. Project Architecture</a><ul><li><a href="#key-code" class="table-of-contents__link toc-highlight">Key Code</a></li><li><a href="#code-analysis" class="table-of-contents__link toc-highlight">Code Analysis</a></li></ul></li><li><a href="#31-configuring-online-llm" class="table-of-contents__link toc-highlight">3.1 Configuring Online LLM</a><ul><li><a href="#32-launching-and-testing-the-functionality" class="table-of-contents__link toc-highlight">3.2 Launching and Testing the Functionality</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">HH-101 Jetson</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://matintechlab.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Matin Tech Lab<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://matin.engineer" target="_blank" rel="noopener noreferrer" class="footer__link-item">Matin Engineer<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/matinmlk/hemihex" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright HemiHex© 2026.</div></div></div></footer></div>
</body>
</html>