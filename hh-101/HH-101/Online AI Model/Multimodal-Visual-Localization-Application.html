<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-hh101 docs-version-current docs-doc-page docs-doc-id-HH-101/Online AI Model/Multimodal-Visual-Localization-Application" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Multimodal visual localization application | HemiHex Docs</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://docs.hemihex.com/img/logo.png"><meta data-rh="true" name="twitter:image" content="https://docs.hemihex.com/img/logo.png"><meta data-rh="true" property="og:url" content="https://docs.hemihex.com/hh-101/HH-101/Online AI Model/Multimodal-Visual-Localization-Application"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-hh101-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-hh101-current"><meta data-rh="true" property="og:title" content="Multimodal visual localization application | HemiHex Docs"><meta data-rh="true" name="description" content="1. Concept Introduction"><meta data-rh="true" property="og:description" content="1. Concept Introduction"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://docs.hemihex.com/hh-101/HH-101/Online AI Model/Multimodal-Visual-Localization-Application"><link data-rh="true" rel="alternate" href="https://docs.hemihex.com/hh-101/HH-101/Online AI Model/Multimodal-Visual-Localization-Application" hreflang="en"><link data-rh="true" rel="alternate" href="https://docs.hemihex.com/hh-101/HH-101/Online AI Model/Multimodal-Visual-Localization-Application" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Multimodal visual localization application","item":"https://docs.hemihex.com/hh-101/HH-101/Online AI Model/Multimodal-Visual-Localization-Application"}]}</script><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="HemiHex Docs RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="HemiHex Docs Atom Feed"><link rel="stylesheet" href="/assets/css/styles.6c03f6b7.css">
<script src="/assets/js/runtime~main.a828d60c.js" defer="defer"></script>
<script src="/assets/js/main.55e05dad.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/logo.png"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/docs/intro"><div class="navbar__logo"><img src="/img/logo.png" alt="HemiHex" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.png" alt="HemiHex" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/hh-101/HH-101/Board Basics Tasks/Jetson-board-introduction">HH-101</a><a class="navbar__item navbar__link" href="/hh-bot/intro">HH-Bot</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/hh-101/HH-101/Board Basics Tasks/Jetson-board-introduction"><span title="Board Basics Tasks" class="categoryLinkLabel_W154">Board Basics Tasks</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/hh-101/HH-101/Linux Basics/linux-basics"><span title="Linux Basics" class="categoryLinkLabel_W154">Linux Basics</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/hh-101/HH-101/GPIO control course/gpio-description-04-gpiocontrolcourse-4-1"><span title="GPIO control course" class="categoryLinkLabel_W154">GPIO control course</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/hh-101/HH-101/Vision Basic Course/csi-camera-preview-05-visionbasiccourse-5-1"><span title="Vision Basic Course" class="categoryLinkLabel_W154">Vision Basic Course</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/hh-101/HH-101/OpenCV/opencv-image-reading"><span title="OpenCV" class="categoryLinkLabel_W154">OpenCV</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/hh-101/HH-101/Advanced Vision/1-1-tensorflow-on-jetson"><span title="Advanced Vision" class="categoryLinkLabel_W154">Advanced Vision</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/hh-101/HH-101/Docker/docker-introduction"><span title="Docker" class="categoryLinkLabel_W154">Docker</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/hh-101/HH-101/ROS1/ros-introduction-core"><span title="ROS1" class="categoryLinkLabel_W154">ROS1</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/hh-101/HH-101/ROS2/ros2-service"><span title="ROS2" class="categoryLinkLabel_W154">ROS2</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/hh-101/HH-101/Offline AI Model/ollama-11-offlineaimodel-11-1"><span title="Offline AI Model" class="categoryLinkLabel_W154">Offline AI Model</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/hh-101/HH-101/Online AI Model/multimodal-visual-understanding-application-12-onlineaimodel-12-2"><span title="Online AI Model" class="categoryLinkLabel_W154">Online AI Model</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/hh-101/HH-101/Online AI Model/multimodal-visual-understanding-application-12-onlineaimodel-12-2"><span title="Multimodal Video Understanding" class="linkLabel_WmDU">Multimodal Video Understanding</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/hh-101/HH-101/Online AI Model/openrouter-api-aggregation-platform-12-onlineaimodel-12-1"><span title="OpenRouter Large Model API Aggregation Platform" class="linkLabel_WmDU">OpenRouter Large Model API Aggregation Platform</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/hh-101/HH-101/Online AI Model/Multimodal-Visual-Localization-Application"><span title="Multimodal visual localization application" class="linkLabel_WmDU">Multimodal visual localization application</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/hh-101/HH-101/Online AI Model/Multimodal-Table-Scanning-Application"><span title="Multimodal table scanning application" class="linkLabel_WmDU">Multimodal table scanning application</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/hh-101/HH-101/Online AI Model/Multimodal-Autonomous-Proxy-Application"><span title="Multimodal autonomous proxy application" class="linkLabel_WmDU">Multimodal autonomous proxy application</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/hh-101/HH-101/Online AI Model/Voice-Interaction-Hardware-Connection"><span title="Voice Interaction Hardware Connection" class="linkLabel_WmDU">Voice Interaction Hardware Connection</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/hh-101/HH-101/Online AI Model/AI-Large-Model-Voice-Interaction"><span title="AI large model voice interaction" class="linkLabel_WmDU">AI large model voice interaction</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/hh-101/HH-101/Online AI Model/Multimodal-Visual-Understanding-Speech-Interaction"><span title="Multimodal visual understand speech interaction" class="linkLabel_WmDU">Multimodal visual understand speech interaction</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/hh-101/HH-101/Online AI Model/Multi-Module-Visual-Position-Application"><span title="Multi module visual position application" class="linkLabel_WmDU">Multi module visual position application</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/hh-101/HH-101/Online AI Model/Multimodal-Table-Scanning-Application-v2"><span title="Multimodal table scanning application-10" class="linkLabel_WmDU">Multimodal table scanning application-10</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/hh-101/HH-101/Online AI Model/Multimodal-Autonomous-Proxy-Application-v2"><span title="Multimodal autonomous proxy application-11" class="linkLabel_WmDU">Multimodal autonomous proxy application-11</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/hh-101/HH-101/Online AI Model/Online-Speech-to-Text-ASR"><span title="Online speech to text (ASR)" class="linkLabel_WmDU">Online speech to text (ASR)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/hh-101/HH-101/Online AI Model/AI-Large-Model-Online-Voice-Assistant"><span title="AI large model online voice assistant" class="linkLabel_WmDU">AI large model online voice assistant</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/hh-101/HH-101/NVIDIA Isaac ROS Course/Build-Isaac-ROS-Environment"><span title="NVIDIA Isaac ROS Course" class="categoryLinkLabel_W154">NVIDIA Isaac ROS Course</span></a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Online AI Model</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Multimodal visual localization application</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>3.Multimodal visual localization application</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-concept-introduction">1. Concept Introduction<a href="#1-concept-introduction" class="hash-link" aria-label="Direct link to 1. Concept Introduction" title="Direct link to 1. Concept Introduction" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="11-what-is-multimodal-visual-localization">1.1 What is &quot;Multimodal Visual Localization&quot;?<a href="#11-what-is-multimodal-visual-localization" class="hash-link" aria-label="Direct link to 1.1 What is &quot;Multimodal Visual Localization&quot;?" title="Direct link to 1.1 What is &quot;Multimodal Visual Localization&quot;?" translate="no">​</a></h3>
<p><strong>Multimodal visual localization</strong>is a technology that combines multiple sensor inputs (such as cameras, depth sensors, and IMUs) with algorithmic processing techniques to accurately identify and track the position and posture of a device or user in an environment. This technology does not rely solely on a single type of sensor data, but instead integrates information from different perception modalities, thereby improving localization accuracy and robustness.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="12-brief-overview-of-implementation-principles">1.2 Brief Overview of Implementation Principles<a href="#12-brief-overview-of-implementation-principles" class="hash-link" aria-label="Direct link to 1.2 Brief Overview of Implementation Principles" title="Direct link to 1.2 Brief Overview of Implementation Principles" translate="no">​</a></h3>
<ol>
<li class="">Cross-modal Representation Learning : In order for LLMs to be capable of processing visual information, a mechanism must be developed to transform visual signals into a form that the model can understand. This may involve extracting features using convolutional neural networks (CNNs) or other architectures suitable for image processing and mapping them into the same embedding space as text.</li>
<li class="">Joint Training : By designing an appropriate loss function, text and visual data can be trained simultaneously within the same framework, allowing the model to learn to relate to these two modalities. For example, in a question-answering system, answers can be given based on both the provided text question and the associated image content.</li>
<li class="">Visually Guided Language Generation/Understanding : Once effective cross-modal representations are established, visual information can be leveraged to enhance the capabilities of the language model. For example, when given a photo, the model can not only describe what is happening in the image, but also answer specific questions about the scene and even execute instructions based on visual cues (such as navigating to a location).</li>
</ol>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-code-analysis">2. Code Analysis<a href="#2-code-analysis" class="hash-link" aria-label="Direct link to 2. Code Analysis" title="Direct link to 2. Code Analysis" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="key-code">Key Code<a href="#key-code" class="hash-link" aria-label="Direct link to Key Code" title="Direct link to Key Code" translate="no">​</a></h3>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-tools-layer-entry-largemodelutilstools_managerpy">1. Tools Layer Entry (largemodel/utils/tools_manager.py)<a href="#1-tools-layer-entry-largemodelutilstools_managerpy" class="hash-link" aria-label="Direct link to 1. Tools Layer Entry (largemodel/utils/tools_manager.py)" title="Direct link to 1. Tools Layer Entry (largemodel/utils/tools_manager.py)" translate="no">​</a></h4>
<p>The<code>visual_positioning</code>function in this file defines the execution flow of the tool, specifically how it constructs a prompt containing the target object name and formatting requirements.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># From largemodel/utils/tools_manager.py</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">class</span><span class="token plain"> </span><span class="token class-name">ToolsManager</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">visual_positioning</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> args</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">Locate object coordinates in image and save results to MD file.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="display:inline-block;color:#e3116c"></span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">:param args: Arguments containing image path and object name.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">:return: Dictionary with file path and coordinate data.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">node</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">get_logger</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">info</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string-interpolation string" style="color:#e3116c">f&quot;Executing visual_positioning() tool with args: </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">args</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">try</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">image_path </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> args</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">get</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;image_path&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">object_name </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> args</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">get</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;object_name&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ... (path fallback mechanism and parameter checking)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Construct a prompt asking the large model to identify the coordinates of the specified object.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">node</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">language </span><span class="token operator" style="color:#393A34">==</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;zh&#x27;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">prompt </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string-interpolation string" style="color:#e3116c">f&quot;Carefully analyze this image and locate each [object_name]. Return bounding box coordinates in the required format.&quot;</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># translated from Chinese</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">else</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">prompt </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string-interpolation string" style="color:#e3116c">f&quot;Please carefully analyze this image and find the position of all [object_name]...&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ... (Build an independent message context)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">result </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">node</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model_client</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">infer_with_image</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">image_path</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> prompt</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> message</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">message_to_use</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ... (Process and parse the returned coordinate text)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token string" style="color:#e3116c">&quot;file_path&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> md_file_path</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token string" style="color:#e3116c">&quot;coordinates_content&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> coordinates_content</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token string" style="color:#e3116c">&quot;explanation_content&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> explanation_content</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ... (error handling)</span><br></span></code></pre></div></div>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-model-interface-layer-largemodelutilslarge_model_interfacepy">2. Model interface layer (largemodel/utils/large_model_interface.py)<a href="#2-model-interface-layer-largemodelutilslarge_model_interfacepy" class="hash-link" aria-label="Direct link to 2. Model interface layer (largemodel/utils/large_model_interface.py)" title="Direct link to 2. Model interface layer (largemodel/utils/large_model_interface.py)" translate="no">​</a></h4>
<p>The<code>infer_with_image</code>function in this file is the unified entry point for all image-related tasks.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># From largemodel/utils/large_model_interface.py</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">class</span><span class="token plain"> </span><span class="token class-name">model_interface</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">infer_with_image</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> image_path</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> text</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">None</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> message</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">None</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;Unified image inference interface. &quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ... (Prepare message)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">try</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Determine which specific implementation to call based on the value of self.llm_platform</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">llm_platform </span><span class="token operator" style="color:#393A34">==</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;ollama&#x27;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">response_content </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">ollama_infer</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">messages</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> image_path</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">image_path</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">elif</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">llm_platform </span><span class="token operator" style="color:#393A34">==</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;tongyi&#x27;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ... Calling the logic of the Tongyi model</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">pass</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ... (Logic for other platforms)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token string" style="color:#e3116c">&#x27;response&#x27;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> response_content</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;messages&#x27;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">messages</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">copy</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">}</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="code-analysis">Code Analysis<a href="#code-analysis" class="hash-link" aria-label="Direct link to Code Analysis" title="Direct link to Code Analysis" translate="no">​</a></h3>
<p>The core of the visual positioning function lies in<strong>guiding large models to output structured data through precise instructions</strong>. It also follows the layered design of the tool layer and the model interface layer.</p>
<ol>
<li class="">Tools Layer ( tools_manager.py ): The visual_positioning function is the core of this function. It accepts two key parameters: image_path (the image path) and object_name (the name of the object to be positioned). The core operation of this function is building a highly customized prompt . It doesn&#x27;t simply ask the model to describe an image. Instead, it embeds object_name into a carefully designed template, explicitly instructing the model to &quot;locate each [object_name] in the image,&quot; and implicitly or explicitly requires the results to be returned in a specific format (such as an array of coordinates). After building the prompt, it calls the infer_with_image method of the model interface layer, passing the image and this customized instruction. * After receiving the returned text from the model interface layer, it needs to perform post-processing : using methods such as regular expressions to parse the model&#x27;s natural language response to extract precise coordinate data. Finally, it returns the parsed structured coordinate data to the upper-layer application.</li>
<li class="">Model Interface Layer ( large_model_interface.py ) : The infer_with_image function still serves as the &quot;dispatching center.&quot; It receives the image and prompt from visual_positioning and dispatches the task to the correct backend model implementation based on the current configuration ( self.llm_platform ). For visual positioning tasks, the model interface layer&#x27;s responsibilities are essentially the same as for visual understanding tasks: correctly packaging the image data and text instructions, sending them to the selected model platform, and then returning the returned text results intact to the tool layer. All platform-specific implementation details are encapsulated in this layer.</li>
</ol>
<p>In summary, the general workflow for visual localization is: ToolsManager receives the target object name and constructs a precise prompt requesting coordinates. ToolsManager calls the model interface. ModelInterface packages the image and prompt together and sends them to the corresponding model platform according to the configuration. The model returns a text file containing the coordinates. ModelInterface returns this text file to ToolsManager. ToolsManager parses the text file, extracts the structured coordinate data, and returns it. This process demonstrates how Prompt Engineering can be used to enable a general large-scale visual model to accomplish more specific and structured tasks.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-practical-application">3. Practical Application<a href="#3-practical-application" class="hash-link" aria-label="Direct link to 3. Practical Application" title="Direct link to 3. Practical Application" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="31-configuring-online-llm">3.1 Configuring Online LLM<a href="#31-configuring-online-llm" class="hash-link" aria-label="Direct link to 3.1 Configuring Online LLM" title="Direct link to 3.1 Configuring Online LLM" translate="no">​</a></h3>
<ol>
<li class="">First, obtain the API key from any platform described in the previous tutorial.</li>
<li class="">Next, update the key in the configuration file. Open the model interface configuration file, large_model_interface.yaml : xxxxxxxxxx vim ~/hemihex_ws/src/largemodel/config/large_model_interface.yaml</li>
<li class="">Enter your API Key : Find the corresponding section and paste the API Key you just copied. This example uses the Tongyi Qianwen configuration. xxxxxxxxxx # large_model_interface.yaml  ## Thousand Questions on Tongyi qianwen_api_key : &quot;sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&quot; # Paste your Key qianwen_model : &quot;qwen-vl-max-latest&quot; # You can choose the model as needed, such asqwen-turbo, qwen-plus</li>
<li class="">Open the main configuration file HemiHex.yaml : xxxxxxxxxx vim ~/hemihex_ws/src/largemodel/config/HemiHex.yaml</li>
<li class="">Select the online platform you want to use : Change the llm_platform parameter to the platform name you want to use. xxxxxxxxxx # HemiHex.yaml  model_service : ros__parameters : # ... llm_platform : &#x27;tongyi&#x27; #Optional platforms: &#x27;ollama&#x27;, &#x27;tongyi&#x27;, &#x27;spark&#x27;, &#x27;qianfan&#x27;, &#x27;openrouter&#x27;</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="32-starting-and-testing-the-function">3.2 Starting and Testing the Function<a href="#32-starting-and-testing-the-function" class="hash-link" aria-label="Direct link to 3.2 Starting and Testing the Function" title="Direct link to 3.2 Starting and Testing the Function" translate="no">​</a></h3>
<ol>
<li class="">Prepare the image file :</li>
</ol>
<p>Place the image file to be tested in the following path:<code>/home/jetson/hemihex_ws/src/largemodel/resources_file/visual_positioning</code></p>
<p>Then name the image<code>test_image.jpg</code></p>
<ol>
<li class="">Start the largemodel main program :</li>
</ol>
<p>Open a terminal and run the following command:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">ros2 launch largemodel largemodel_control.launch.py text_chat_mode:=true</span><br></span></code></pre></div></div>
<ol>
<li class="">Send a text command : Open another terminal and run the following command:</li>
</ol>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">ros2 run text_chat text_chat</span><br></span></code></pre></div></div>
<p>Then start typing: &quot;Analyze the position of the dinosaur in the image.&quot;</p>
<ol>
<li class="">Observe the results : In the first terminal running the main program, you will see log output indicating that the system received the command, called the visual_positioning tool, completed the execution, and saved the coordinates to a file.</li>
</ol>
<p>This file can be found in the ~/hemihex_ws/src/largemodel/resources_file/visual_positioning directory.</p></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/hh-101/HH-101/Online AI Model/openrouter-api-aggregation-platform-12-onlineaimodel-12-1"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">OpenRouter Large Model API Aggregation Platform</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/hh-101/HH-101/Online AI Model/Multimodal-Table-Scanning-Application"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Multimodal table scanning application</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#1-concept-introduction" class="table-of-contents__link toc-highlight">1. Concept Introduction</a><ul><li><a href="#11-what-is-multimodal-visual-localization" class="table-of-contents__link toc-highlight">1.1 What is &quot;Multimodal Visual Localization&quot;?</a></li><li><a href="#12-brief-overview-of-implementation-principles" class="table-of-contents__link toc-highlight">1.2 Brief Overview of Implementation Principles</a></li></ul></li><li><a href="#2-code-analysis" class="table-of-contents__link toc-highlight">2. Code Analysis</a><ul><li><a href="#key-code" class="table-of-contents__link toc-highlight">Key Code</a></li><li><a href="#code-analysis" class="table-of-contents__link toc-highlight">Code Analysis</a></li></ul></li><li><a href="#3-practical-application" class="table-of-contents__link toc-highlight">3. Practical Application</a><ul><li><a href="#31-configuring-online-llm" class="table-of-contents__link toc-highlight">3.1 Configuring Online LLM</a></li><li><a href="#32-starting-and-testing-the-function" class="table-of-contents__link toc-highlight">3.2 Starting and Testing the Function</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">HH-101 Jetson</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://matintechlab.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Matin Tech Lab<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://matin.engineer" target="_blank" rel="noopener noreferrer" class="footer__link-item">Matin Engineer<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/matinmlk/hemihex" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright HemiHex© 2026.</div></div></div></footer></div>
</body>
</html>