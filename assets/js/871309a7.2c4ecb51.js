"use strict";(globalThis.webpackChunkhemihex_docs=globalThis.webpackChunkhemihex_docs||[]).push([[5009],{24873:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>d,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>l,toc:()=>t});const l=JSON.parse('{"id":"HH-101/Offline AI Model/multimodal-video-analysis-application-11-offlineaimodel-11-13","title":"Multimodal Video Analysis Application","description":"1. Concept Introduction","source":"@site/docs/hh101/HH-101/11- Offline AI Model/13-multimodal-video-analysis-application-11-offlineaimodel-11-13.md","sourceDirName":"HH-101/11- Offline AI Model","slug":"/HH-101/Offline AI Model/multimodal-video-analysis-application-11-offlineaimodel-11-13","permalink":"/hh-101/HH-101/Offline AI Model/multimodal-video-analysis-application-11-offlineaimodel-11-13","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":0,"frontMatter":{"title":"Multimodal Video Analysis Application","sidebar_position":0},"sidebar":"hh101Sidebar","previous":{"title":"Multimodal Text Image Application","permalink":"/hh-101/HH-101/Offline AI Model/multimodal-text-image-application-11-offlineaimodel-11-12"},"next":{"title":"Multi-module Visual Position Application","permalink":"/hh-101/HH-101/Offline AI Model/multi-module-visual-position-application-11-offlineaimodel-11-14"}}');var s=a(74848),i=a(28453);const r={title:"Multimodal Video Analysis Application",sidebar_position:0},o="Multimodal Video Analysis Application",d={},t=[{value:"1. Concept Introduction",id:"1-concept-introduction",level:2},{value:"1.1 What is &quot;Video Analysis&quot;?",id:"11-what-is-video-analysis",level:3},{value:"1.2 Implementation Principles",id:"12-implementation-principles",level:3},{value:"2. Code Analysis",id:"2-code-analysis",level:2},{value:"Key Code",id:"key-code",level:3},{value:"1. Tool Layer Entry ( largemodel/utils/tools_manager.py )",id:"1-tool-layer-entry--largemodelutilstools_managerpy-",level:4},{value:"2. Model Interface Layer and Frame Extraction ( largemodel/utils/large_model_interface.py )",id:"2-model-interface-layer-and-frame-extraction--largemodelutilslarge_model_interfacepy-",level:4},{value:"Code Analysis",id:"code-analysis",level:3},{value:"3. Practical Operations",id:"3-practical-operations",level:2},{value:"3.1 Configuring the Offline Large Model",id:"31-configuring-the-offline-large-model",level:3},{value:"3.1.1 Configuring the LLM Platform (HemiHex.yaml)",id:"311-configuring-the-llm-platform-hemihexyaml",level:4},{value:"3.1.2 Configuring the Model Interface ( large_model_interface.yaml )",id:"312-configuring-the-model-interface--large_model_interfaceyaml-",level:4},{value:"3.2 Starting and Testing the Feature (Text Input Mode)",id:"32-starting-and-testing-the-feature-text-input-mode",level:3},{value:"4. Common Problems and Solutions",id:"4-common-problems-and-solutions",level:2},{value:"Problem 1: Error message &quot;Video file not found&quot; or &quot;Unable to extract keyframes from video.&quot;",id:"problem-1-error-message-video-file-not-found-or-unable-to-extract-keyframes-from-video",level:4},{value:"Problem 2: Analyzing a long video is time-consuming.",id:"problem-2-analyzing-a-long-video-is-time-consuming",level:4}];function c(e){const n={admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",p:"p",pre:"pre",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"multimodal-video-analysis-application",children:"Multimodal Video Analysis Application"})}),"\n",(0,s.jsx)(n.h2,{id:"1-concept-introduction",children:"1. Concept Introduction"}),"\n",(0,s.jsx)(n.h3,{id:"11-what-is-video-analysis",children:'1.1 What is "Video Analysis"?'}),"\n",(0,s.jsx)(n.p,{children:"In the largemodel project, the multimodal video analysis feature enables a robot to process a video and summarize its core content, describe key events, or answer specific questions about the video in natural language. This allows the robot to leap from understanding only static images to understanding the dynamic and temporal world."}),"\n",(0,s.jsx)(n.p,{children:'The core tool for this feature is **analyze_video`. When a user provides a video file and asks a question (such as "Summarize what this video says"), the system invokes this tool to process and analyze the video and return a textual response from the AI.'}),"\n",(0,s.jsx)(n.h3,{id:"12-implementation-principles",children:"1.2 Implementation Principles"}),"\n",(0,s.jsx)(n.p,{children:"The core challenge of offline video analysis lies in how to efficiently process video data containing hundreds or thousands of frames. A popular implementation principle is as follows:"}),"\n",(0,s.jsx)(n.p,{children:"Simply put, it condenses a video into a few key images and their sequence, allowing users to understand the entire story like reading a comic strip and answer related questions."}),"\n",(0,s.jsx)(n.h2,{id:"2-code-analysis",children:"2. Code Analysis"}),"\n",(0,s.jsx)(n.h3,{id:"key-code",children:"Key Code"}),"\n",(0,s.jsx)(n.h4,{id:"1-tool-layer-entry--largemodelutilstools_managerpy-",children:"1. Tool Layer Entry ( largemodel/utils/tools_manager.py )"}),"\n",(0,s.jsx)(n.p,{children:"The analyze_video function in this file defines the tool's execution flow."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'xxxxxxxxxx\n# From largemodel/utils/tools_manager.py\nclass\nToolsManager\n:\n# ...\ndef\nanalyze_video\n(\nself\n,\nargs\n):\n"""\nAnalyze video file and provide content description.\n\u5206\u6790\u89c6\u9891\u6587\u4ef6\u5e76\u63d0\u4f9b\u5185\u5bb9\u63cf\u8ff0\u3002\n:param args: Arguments containing video path.\n:return: Dictionary with video description and path.\n"""\nself\n.\nnode\n.\nget_logger\n().\ninfo\n(\nf"Executing analyze_video() tool with args: {args}"\n)\ntry\n:\nvideo_path\n=\nargs\n.\nget\n(\n"video_path"\n)\n# ... (\u667a\u80fd\u8def\u5f84\u56de\u9000\u673a\u5236)\nif\nvideo_path\nand\nos\n.\npath\n.\nexists\n(\nvideo_path\n):\n# ... (\u6784\u5efaPrompt)\n# Use a fully isolated, one-time context for video analysis to ensure a plain text description. / \u4f7f\u7528\u5b8c\u5168\u9694\u79bb\u7684\u4e00\u6b21\u6027\u4e0a\u4e0b\u6587\u8fdb\u884c\u89c6\u9891\u5206\u6790\uff0c\u4ee5\u786e\u4fdd\u83b7\u5f97\u7eaf\u6587\u672c\u63cf\u8ff0\u3002\nsimple_context\n= [{\n"role"\n:\n"system"\n,\n"content"\n:\n"You are a video description assistant. ..."\n}]\nresult\n=\nself\n.\nnode\n.\nmodel_client\n.\ninfer_with_video\n(\nvideo_path\n,\nprompt\n,\nmessage\n=\nsimple_context\n)\n# ... (\u5904\u7406\u7ed3\u679c)\nreturn\n{\n"description"\n:\ndescription\n,\n"video_path"\n:\nvideo_path\n}\n# ... (\u9519\u8bef\u5904\u7406)\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"xxxxxxxxxx\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# From largemodel/utils/tools_manager.py\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"class\nToolsManager\n:\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# ...\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"def\nanalyze_video\n(\nself\n,\nargs\n):\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'"""\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"Analyze video file and provide content description.\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"\u5206\u6790\u89c6\u9891\u6587\u4ef6\u5e76\u63d0\u4f9b\u5185\u5bb9\u63cf\u8ff0\u3002\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:":param args: Arguments containing video path.\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:":return: Dictionary with video description and path.\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'"""\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'self\n.\nnode\n.\nget_logger\n().\ninfo\n(\nf"Executing analyze_video() tool with args: {args}"\n)\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"try\n:\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'video_path\n=\nargs\n.\nget\n(\n"video_path"\n)\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# ... (\u667a\u80fd\u8def\u5f84\u56de\u9000\u673a\u5236)\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"if\nvideo_path\nand\nos\n.\npath\n.\nexists\n(\nvideo_path\n):\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# ... (\u6784\u5efaPrompt)\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Use a fully isolated, one-time context for video analysis to ensure a plain text description. / \u4f7f\u7528\u5b8c\u5168\u9694\u79bb\u7684\u4e00\u6b21\u6027\u4e0a\u4e0b\u6587\u8fdb\u884c\u89c6\u9891\u5206\u6790\uff0c\u4ee5\u786e\u4fdd\u83b7\u5f97\u7eaf\u6587\u672c\u63cf\u8ff0\u3002\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"simple_context\n= [{\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'"role"\n:\n"system"\n,\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'"content"\n:\n"You are a video description assistant. ..."\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"}]\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"result\n=\nself\n.\nnode\n.\nmodel_client\n.\ninfer_with_video\n(\nvideo_path\n,\nprompt\n,\nmessage\n=\nsimple_context\n)\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# ... (\u5904\u7406\u7ed3\u679c)\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"return\n{\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'"description"\n:\ndescription\n,\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'"video_path"\n:\nvideo_path\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"}\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# ... (\u9519\u8bef\u5904\u7406)\n"})}),"\n",(0,s.jsx)(n.h4,{id:"2-model-interface-layer-and-frame-extraction--largemodelutilslarge_model_interfacepy-",children:"2. Model Interface Layer and Frame Extraction ( largemodel/utils/large_model_interface.py )"}),"\n",(0,s.jsx)(n.p,{children:"The functions in this file are responsible for processing video files and passing them to the underlying model."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'xxxxxxxxxx\n# From largemodel/utils/large_model_interface.py\n\u200b\nclass\nmodel_interface\n:\n# ...\ndef\ninfer_with_video\n(\nself\n,\nvideo_path\n,\ntext\n=\nNone\n,\nmessage\n=\nNone\n):\n"""Unified video inference interface. / \u7edf\u4e00\u7684\u89c6\u9891\u63a8\u7406\u63a5\u53e3\u3002"""\n# ... (\u51c6\u5907\u6d88\u606f)\ntry\n:\n# \u6839\u636e self.llm_platform \u51b3\u5b9a\u8c03\u7528\u54ea\u4e2a\u5177\u4f53\u5b9e\u73b0\nif\nself\n.\nllm_platform\n==\n\'ollama\'\n:\nresponse_content\n=\nself\n.\nollama_infer\n(\nself\n.\nmessages\n,\nvideo_path\n=\nvideo_path\n)\n# ... (\u5176\u4ed6\u5728\u7ebf\u5e73\u53f0\u7684\u903b\u8f91)\n# ...\nreturn\n{\n\'response\'\n:\nresponse_content\n,\n\'messages\'\n:\nself\n.\nmessages\n.\ncopy\n()}\n\u200b\ndef\n_extract_video_frames\n(\nself\n,\nvideo_path\n,\nmax_frames\n=\n5\n):\n"""Extract keyframes from a video for analysis. / \u4ece\u89c6\u9891\u4e2d\u63d0\u53d6\u5173\u952e\u5e27\u7528\u4e8e\u5206\u6790\u3002"""\ntry\n:\nimport\ncv2\n# ... (\u89c6\u9891\u8bfb\u53d6\u548c\u5e27\u95f4\u9694\u8ba1\u7b97)\nwhile\nextracted_count\n<\nmax_frames\n:\n# ... (\u5faa\u73af\u8bfb\u53d6\u89c6\u9891\u5e27)\nif\nframe_count\n%\nframe_interval\n==\n0\n:\n# ... (\u5c06\u5e27\u4fdd\u5b58\u4e3a\u4e34\u65f6\u56fe\u7247)\nframe_base64\n=\nself\n.\nencode_file_to_base64\n(\ntemp_path\n)\nframe_images\n.\nappend\n(\nframe_base64\n)\n# ...\nreturn\nframe_images\n# ... (\u5f02\u5e38\u5904\u7406)\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"xxxxxxxxxx\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# From largemodel/utils/large_model_interface.py\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"class\nmodel_interface\n:\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# ...\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"def\ninfer_with_video\n(\nself\n,\nvideo_path\n,\ntext\n=\nNone\n,\nmessage\n=\nNone\n):\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'"""Unified video inference interface. / \u7edf\u4e00\u7684\u89c6\u9891\u63a8\u7406\u63a5\u53e3\u3002"""\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# ... (\u51c6\u5907\u6d88\u606f)\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"try\n:\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# \u6839\u636e self.llm_platform \u51b3\u5b9a\u8c03\u7528\u54ea\u4e2a\u5177\u4f53\u5b9e\u73b0\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"if\nself\n.\nllm_platform\n==\n'ollama'\n:\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"response_content\n=\nself\n.\nollama_infer\n(\nself\n.\nmessages\n,\nvideo_path\n=\nvideo_path\n)\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# ... (\u5176\u4ed6\u5728\u7ebf\u5e73\u53f0\u7684\u903b\u8f91)\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# ...\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"return\n{\n'response'\n:\nresponse_content\n,\n'messages'\n:\nself\n.\nmessages\n.\ncopy\n()}\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"def\n_extract_video_frames\n(\nself\n,\nvideo_path\n,\nmax_frames\n=\n5\n):\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'"""Extract keyframes from a video for analysis. / \u4ece\u89c6\u9891\u4e2d\u63d0\u53d6\u5173\u952e\u5e27\u7528\u4e8e\u5206\u6790\u3002"""\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"try\n:\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"import\ncv2\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# ... (\u89c6\u9891\u8bfb\u53d6\u548c\u5e27\u95f4\u9694\u8ba1\u7b97)\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"while\nextracted_count\n<\nmax_frames\n:\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# ... (\u5faa\u73af\u8bfb\u53d6\u89c6\u9891\u5e27)\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"if\nframe_count\n%\nframe_interval\n==\n0\n:\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# ... (\u5c06\u5e27\u4fdd\u5b58\u4e3a\u4e34\u65f6\u56fe\u7247)\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"frame_base64\n=\nself\n.\nencode_file_to_base64\n(\ntemp_path\n)\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"frame_images\n.\nappend\n(\nframe_base64\n)\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# ...\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"return\nframe_images\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# ... (\u5f02\u5e38\u5904\u7406)\n"})}),"\n",(0,s.jsx)(n.h3,{id:"code-analysis",children:"Code Analysis"}),"\n",(0,s.jsx)(n.p,{children:"The implementation of video analysis is more complex than image analysis. It requires a key preprocessing step at the model interface layer: frame extraction."}),"\n",(0,s.jsx)(n.p,{children:"In summary, the general process of video analysis is: ToolsManager initiates an analysis request -> model_interface intercepts the request and calls _extract_video_frames to decompose the video file into multiple keyframe images -> model_interface sends these images, along with analysis instructions, to the corresponding model platform according to the configuration -> the model returns a comprehensive description of the video -> the results are finally returned to ToolsManager . This design ensures the stability and versatility of upper-layer applications."}),"\n",(0,s.jsx)(n.h2,{id:"3-practical-operations",children:"3. Practical Operations"}),"\n",(0,s.jsx)(n.h3,{id:"31-configuring-the-offline-large-model",children:"3.1 Configuring the Offline Large Model"}),"\n",(0,s.jsx)(n.h4,{id:"311-configuring-the-llm-platform-hemihexyaml",children:"3.1.1 Configuring the LLM Platform (HemiHex.yaml)"}),"\n",(0,s.jsx)(n.p,{children:"This file determines which large model platform the model_service node loads as its primary language model."}),"\n",(0,s.jsx)(n.p,{children:"Open the file in the terminal :"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"xxxxxxxxxx\nvim\n~/yahboom_ws/src/largemodel/config/HemiHex.yaml\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"xxxxxxxxxx\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"vim\n~/yahboom_ws/src/largemodel/config/HemiHex.yaml\n"})}),"\n",(0,s.jsx)(n.p,{children:"Modify/confirm llm_platform :"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"xxxxxxxxxx\nmodel_service\n:\n#\u6a21\u578b\u670d\u52a1\u5668\u8282\u70b9\u53c2\u6570 Model server node parameters\nros__parameters\n:\nlanguage\n:\n'en'\n#\u5927\u6a21\u578b\u63a5\u53e3\u8bed\u8a00 Large Model Interface Language\nuseolinetts\n:\nFalse\n#\u6587\u5b57\u6a21\u5f0f\u4e0b\u6b64\u9879\u65e0\u6548\uff0c\u53ef\u5ffd\u7565 This item is invalid in text mode and can be ignored\n\u200b\n# \u5927\u6a21\u578b\u914d\u7f6e Large model configuration\nllm_platform\n:\n'ollama'\n# \u5173\u952e: \u786e\u4fdd\u8fd9\u91cc\u662f 'ollama' Key: Make sure it's 'ollama'\nregional_setting\n:\n\"international\"\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"xxxxxxxxxx\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"model_service\n:\n#\u6a21\u578b\u670d\u52a1\u5668\u8282\u70b9\u53c2\u6570 Model server node parameters\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"ros__parameters\n:\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"language\n:\n'en'\n#\u5927\u6a21\u578b\u63a5\u53e3\u8bed\u8a00 Large Model Interface Language\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"useolinetts\n:\nFalse\n#\u6587\u5b57\u6a21\u5f0f\u4e0b\u6b64\u9879\u65e0\u6548\uff0c\u53ef\u5ffd\u7565 This item is invalid in text mode and can be ignored\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# \u5927\u6a21\u578b\u914d\u7f6e Large model configuration\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"llm_platform\n:\n'ollama'\n# \u5173\u952e: \u786e\u4fdd\u8fd9\u91cc\u662f 'ollama' Key: Make sure it's 'ollama'\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'regional_setting\n:\n"international"\n'})}),"\n",(0,s.jsx)(n.h4,{id:"312-configuring-the-model-interface--large_model_interfaceyaml-",children:"3.1.2 Configuring the Model Interface ( large_model_interface.yaml )"}),"\n",(0,s.jsx)(n.p,{children:"This file defines which visual model to use when the ollama platform is selected."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"xxxxxxxxxx\nvim ~/yahboom_ws/src/largemodel/config/large_model_interface.yaml\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"xxxxxxxxxx\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"vim ~/yahboom_ws/src/largemodel/config/large_model_interface.yaml\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'xxxxxxxxxx\n#.....\n## \u79bb\u7ebf\u5927\u6a21\u578b (Offline Large Language Models)\n# Ollama Configuration\nollama_host:\n"http://localhost:11434"\n# Ollama server address\nollama_model:\n"llava"\n# Key: Change this to the multimodal model you downloaded, such as "llava"\n#.....\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"xxxxxxxxxx\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"#.....\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"## \u79bb\u7ebf\u5927\u6a21\u578b (Offline Large Language Models)\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Ollama Configuration\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'ollama_host:\n"http://localhost:11434"\n# Ollama server address\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'ollama_model:\n"llava"\n# Key: Change this to the multimodal model you downloaded, such as "llava"\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"#.....\n"})}),"\n",(0,s.jsx)(n.p,{children:"Note : Please ensure that the model specified in the configuration parameters (e.g., llava ) can handle multimodal input."}),"\n",(0,s.jsx)(n.h3,{id:"32-starting-and-testing-the-feature-text-input-mode",children:"3.2 Starting and Testing the Feature (Text Input Mode)"}),"\n",(0,s.jsx)(n.admonition,{type:"warning",children:(0,s.jsx)(n.p,{children:"Due to performance limitations, the Jetson Orin Nano 4GB may not perform well. To experience this feature, please refer to the corresponding section in [Online Large Model (Text Interaction)]"})}),"\n",(0,s.jsx)(n.p,{children:"Prepare video files :"}),"\n",(0,s.jsx)(n.p,{children:"Place a video file to test in the following path: /home/jetson/yahboom_ws/src/largemodel/resources_file/analyze_video"}),"\n",(0,s.jsx)(n.p,{children:"Then name the video test_video.mp4"}),"\n",(0,s.jsx)(n.p,{children:"Start the largemodel main program (in text mode):"}),"\n",(0,s.jsx)(n.p,{children:"Open a terminal and run the following command:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"xxxxxxxxxx\nros2 launch largemodel largemodel_control.launch.py text_chat_mode:=true\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"xxxxxxxxxx\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"ros2 launch largemodel largemodel_control.launch.py text_chat_mode:=true\n"})}),"\n",(0,s.jsx)(n.p,{children:"Send text command : Open another terminal again and run the following command,"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"xxxxxxxxxx\nros2 run text_chat text_chat\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"xxxxxxxxxx\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"ros2 run text_chat text_chat\n"})}),"\n",(0,s.jsx)(n.p,{children:'Then start typing text: "Analyze this video."'}),"\n",(0,s.jsx)(n.p,{children:"Observation results : In the first terminal running the main program, you will see log output showing that the system received the command, called the analyze_video tool, extracted the keyframes, and finally printed out the AI's summary of the video content."}),"\n",(0,s.jsx)(n.h2,{id:"4-common-problems-and-solutions",children:"4. Common Problems and Solutions"}),"\n",(0,s.jsx)(n.h4,{id:"problem-1-error-message-video-file-not-found-or-unable-to-extract-keyframes-from-video",children:'Problem 1: Error message "Video file not found" or "Unable to extract keyframes from video."'}),"\n",(0,s.jsx)(n.p,{children:"Solution :"}),"\n",(0,s.jsx)(n.h4,{id:"problem-2-analyzing-a-long-video-is-time-consuming",children:"Problem 2: Analyzing a long video is time-consuming."}),"\n",(0,s.jsx)(n.p,{children:"Solution :"})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},28453:(e,n,a)=>{a.d(n,{R:()=>r,x:()=>o});var l=a(96540);const s={},i=l.createContext(s);function r(e){const n=l.useContext(i);return l.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),l.createElement(i.Provider,{value:n},e.children)}}}]);