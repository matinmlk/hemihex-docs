"use strict";(globalThis.webpackChunkhemihex_docs=globalThis.webpackChunkhemihex_docs||[]).push([[7439],{28453:(n,e,s)=>{s.d(e,{R:()=>i,x:()=>c});var a=s(96540);const l={},r=a.createContext(l);function i(n){const e=a.useContext(r);return a.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function c(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(l):n.components||l:i(n.components),a.createElement(r.Provider,{value:e},n.children)}},42652:(n,e,s)=>{s.r(e),s.d(e,{assets:()=>o,contentTitle:()=>c,default:()=>h,frontMatter:()=>i,metadata:()=>a,toc:()=>t});const a=JSON.parse('{"id":"HH-101/Offline AI Model/offline-speech-to-text-asr-11-offlineaimodel-11-18","title":"Offline Speech to Text (ASR)","description":"1. Introduction","source":"@site/docs/hh101/HH-101/11- Offline AI Model/18-offline-speech-to-text-asr-11-offlineaimodel-11-18.md","sourceDirName":"HH-101/11- Offline AI Model","slug":"/HH-101/Offline AI Model/offline-speech-to-text-asr-11-offlineaimodel-11-18","permalink":"/hh-101/HH-101/Offline AI Model/offline-speech-to-text-asr-11-offlineaimodel-11-18","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":0,"frontMatter":{"title":"Offline Speech to Text (ASR)","sidebar_position":0},"sidebar":"hh101Sidebar","previous":{"title":"Voice Interaction Hardware Connection","permalink":"/hh-101/HH-101/Offline AI Model/voice-interaction-hardware-connection-11-offlineaimodel-11-17"},"next":{"title":"Offline Text to Speech (TTS)","permalink":"/hh-101/HH-101/Offline AI Model/offline-text-to-speech-tts-11-offlineaimodel-11-19"}}');var l=s(74848),r=s(28453);const i={title:"Offline Speech to Text (ASR)",sidebar_position:0},c="1.Offline speech to text (ASR)",o={},t=[{value:"1. Introduction",id:"1-introduction",level:2},{value:"1.1 What is &quot;ASR&quot;?",id:"11-what-is-asr",level:3},{value:"1.2 Implementation Principles",id:"12-implementation-principles",level:3},{value:"1. Acoustic Model",id:"1-acoustic-model",level:4},{value:"2. Language Model",id:"2-language-model",level:4},{value:"3. Pronunciation Dictionary",id:"3-pronunciation-dictionary",level:4},{value:"4. Decoder",id:"4-decoder",level:4},{value:"5. End-to-End ASR",id:"5-end-to-end-asr",level:4},{value:"2. Code Analysis",id:"2-code-analysis",level:2},{value:"Key Code",id:"key-code",level:3},{value:"1. Speech Processing and Recognition Core ( largemodel/largemodel/asr.py )",id:"1-speech-processing-and-recognition-core--largemodellargemodelasrpy-",level:4},{value:"2. VAD smart recording ( largemodel/largemodel/asr.py )",id:"2-vad-smart-recording--largemodellargemodelasrpy-",level:4},{value:"Code Analysis",id:"code-analysis",level:3},{value:"3. Practical Operations",id:"3-practical-operations",level:2},{value:"3.1 Configuring Offline ASR",id:"31-configuring-offline-asr",level:3},{value:"3.2 Start and test the functionality",id:"32-start-and-test-the-functionality",level:3}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",p:"p",pre:"pre",...(0,r.R)(),...n.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(e.header,{children:(0,l.jsx)(e.h1,{id:"1offline-speech-to-text-asr",children:"1.Offline speech to text (ASR)"})}),"\n",(0,l.jsx)(e.h2,{id:"1-introduction",children:"1. Introduction"}),"\n",(0,l.jsx)(e.h3,{id:"11-what-is-asr",children:'1.1 What is "ASR"?'}),"\n",(0,l.jsx)(e.p,{children:'ASR (Automatic Speech Recognition) is a technology that converts human speech signals into text. It is widely used in intelligent assistants, voice command control, telephone customer service automation, and real-time subtitle generation. The goal of ASR is to enable machines to "understand" human speech and convert it into a form that computers can process and understand.'}),"\n",(0,l.jsx)(e.h3,{id:"12-implementation-principles",children:"1.2 Implementation Principles"}),"\n",(0,l.jsx)(e.p,{children:"The implementation of an ASR system relies primarily on the following key technical components:"}),"\n",(0,l.jsx)(e.h4,{id:"1-acoustic-model",children:"1. Acoustic Model"}),"\n",(0,l.jsx)(e.h4,{id:"2-language-model",children:"2. Language Model"}),"\n",(0,l.jsx)(e.h4,{id:"3-pronunciation-dictionary",children:"3. Pronunciation Dictionary"}),"\n",(0,l.jsx)(e.h4,{id:"4-decoder",children:"4. Decoder"}),"\n",(0,l.jsx)(e.h4,{id:"5-end-to-end-asr",children:"5. End-to-End ASR"}),"\n",(0,l.jsx)(e.p,{children:"In general, modern ASR systems achieve efficient and accurate speech-to-text conversion by combining the aforementioned components and leveraging large datasets and powerful computing resources for training. With technological advances, the performance of ASR systems continues to improve, and their application scenarios are becoming increasingly broad."}),"\n",(0,l.jsx)(e.p,{children:"--"}),"\n",(0,l.jsx)(e.h2,{id:"2-code-analysis",children:"2. Code Analysis"}),"\n",(0,l.jsx)(e.h3,{id:"key-code",children:"Key Code"}),"\n",(0,l.jsx)(e.h4,{id:"1-speech-processing-and-recognition-core--largemodellargemodelasrpy-",children:"1. Speech Processing and Recognition Core ( largemodel/largemodel/asr.py )"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"xxxxxxxxxx\n# From largemodel/largemodel/asr.py\ndef\nkws_handler\n(\nself\n)\n->\nNone\n:\nif\nself\n.\nstop_event\n.\nis_set\n():\nreturn\n\u200b\nif\nself\n.\nlisten_for_speech\n(\nself\n.\nmic_index\n):\nasr_text\n=\nself\n.\nASR_conversion\n(\nself\n.\nuser_speechdir\n)\n# \u8fdb\u884c ASR \u8f6c\u6362 / Perform ASR conversion\nif\nasr_text\n==\n'error'\n:\n# \u68c0\u67e5 ASR \u7ed3\u679c\u957f\u5ea6\u662f\u5426\u5c0f\u4e8e4\u4e2a\u5b57\u7b26 / Check if ASR result length is less than 4 characters\nself\n.\nget_logger\n().\nwarn\n(\n\"I still don't understand what you mean. Please try again\"\n)\nplaysound\n(\nself\n.\naudio_dict\n[\nself\n.\nerror_response\n])\n# \u9519\u8bef\u54cd\u5e94 / Error response\nelse\n:\nself\n.\nget_logger\n().\ninfo\n(\nasr_text\n)\nself\n.\nget_logger\n().\ninfo\n(\n\"okay\ud83d\ude00, let me think for a moment...\"\n)\nself\n.\nasr_pub_result\n(\nasr_text\n)\n# \u53d1\u5e03 ASR\u7ed3\u679c / Publish ASR result\nelse\n:\nreturn\n\u200b\ndef\nASR_conversion\n(\nself\n,\ninput_file\n:\nstr\n)\n->\nstr\n:\nif\nself\n.\nuse_oline_asr\n:\nresult\n=\nself\n.\nmodelinterface\n.\noline_asr\n(\ninput_file\n)\nif\nresult\n[\n0\n] ==\n'ok'\nand\nlen\n(\nresult\n[\n1\n])\n>\n4\n:\nreturn\nresult\n[\n1\n]\nelse\n:\nself\n.\nget_logger\n().\nerror\n(\nf'ASR Error:{result[1]}'\n)\n# ASR error.\nreturn\n'error'\nelse\n:\nresult\n=\nself\n.\nmodelinterface\n.\nSenseVoiceSmall_ASR\n(\ninput_file\n)\nif\nresult\n[\n0\n] ==\n'ok'\nand\nlen\n(\nresult\n[\n1\n])\n>\n4\n:\nreturn\nresult\n[\n1\n]\nelse\n:\nself\n.\nget_logger\n().\nerror\n(\nf'ASR Error:{result[1]}'\n)\n# ASR error.\nreturn\n'error'\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"xxxxxxxxxx\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"# From largemodel/largemodel/asr.py\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"def\nkws_handler\n(\nself\n)\n->\nNone\n:\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"if\nself\n.\nstop_event\n.\nis_set\n():\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"return\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"\u200b\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"if\nself\n.\nlisten_for_speech\n(\nself\n.\nmic_index\n):\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"asr_text\n=\nself\n.\nASR_conversion\n(\nself\n.\nuser_speechdir\n)\n# \u8fdb\u884c ASR \u8f6c\u6362 / Perform ASR conversion\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"if\nasr_text\n==\n'error'\n:\n# \u68c0\u67e5 ASR \u7ed3\u679c\u957f\u5ea6\u662f\u5426\u5c0f\u4e8e4\u4e2a\u5b57\u7b26 / Check if ASR result length is less than 4 characters\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:'self\n.\nget_logger\n().\nwarn\n(\n"I still don\'t understand what you mean. Please try again"\n)\n'})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"playsound\n(\nself\n.\naudio_dict\n[\nself\n.\nerror_response\n])\n# \u9519\u8bef\u54cd\u5e94 / Error response\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"else\n:\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"self\n.\nget_logger\n().\ninfo\n(\nasr_text\n)\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:'self\n.\nget_logger\n().\ninfo\n(\n"okay\ud83d\ude00, let me think for a moment..."\n)\n'})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"self\n.\nasr_pub_result\n(\nasr_text\n)\n# \u53d1\u5e03 ASR\u7ed3\u679c / Publish ASR result\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"else\n:\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"return\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"\u200b\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"def\nASR_conversion\n(\nself\n,\ninput_file\n:\nstr\n)\n->\nstr\n:\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"if\nself\n.\nuse_oline_asr\n:\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"result\n=\nself\n.\nmodelinterface\n.\noline_asr\n(\ninput_file\n)\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"if\nresult\n[\n0\n] ==\n'ok'\nand\nlen\n(\nresult\n[\n1\n])\n>\n4\n:\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"return\nresult\n[\n1\n]\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"else\n:\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"self\n.\nget_logger\n().\nerror\n(\nf'ASR Error:{result[1]}'\n)\n# ASR error.\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"return\n'error'\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"else\n:\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"result\n=\nself\n.\nmodelinterface\n.\nSenseVoiceSmall_ASR\n(\ninput_file\n)\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"if\nresult\n[\n0\n] ==\n'ok'\nand\nlen\n(\nresult\n[\n1\n])\n>\n4\n:\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"return\nresult\n[\n1\n]\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"else\n:\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"self\n.\nget_logger\n().\nerror\n(\nf'ASR Error:{result[1]}'\n)\n# ASR error.\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"return\n'error'\n"})}),"\n",(0,l.jsx)(e.h4,{id:"2-vad-smart-recording--largemodellargemodelasrpy-",children:"2. VAD smart recording ( largemodel/largemodel/asr.py )"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"xxxxxxxxxx\n# From largemodel/largemodel/asr.py\ndef\nlisten_for_speech\n(\nself\n,\nmic_index\n=\n0\n):\np\n=\npyaudio\n.\nPyAudio\n()\n# Create PyAudio instance. / \u521b\u5efaPyAudio\u5b9e\u4f8b\u3002\naudio_buffer\n= []\n# Store audio data. / \u5b58\u50a8\u97f3\u9891\u6570\u636e\u3002\nsilence_counter\n=\n0\n# Silence counter. / \u9759\u97f3\u8ba1\u6570\u5668\u3002\nMAX_SILENCE_FRAMES\n=\n90\n# 30\u5e27*30ms=900ms\u9759\u97f3\u540e\u505c\u6b62 / Stop after 900ms of silence (30 frames * 30ms)\nspeaking\n=\nFalse\n# Flag indicating speech activity. / \u8bed\u97f3\u6d3b\u52a8\u6807\u5fd7\u3002\nframe_counter\n=\n0\n# Frame counter. / \u8ba1\u6570\u5668\u3002\nstream_kwargs\n= {\n'format'\n:\npyaudio\n.\npaInt16\n,\n'channels'\n:\n1\n,\n'rate'\n:\nself\n.\nsample_rate\n,\n'input'\n:\nTrue\n,\n'frames_per_buffer'\n:\nself\n.\nframe_bytes\n,\n}\nif\nmic_index\n!\n=\n0\n:\nstream_kwargs\n[\n'input_device_index'\n] =\nmic_index\n\u200b\n# Prompt the user to speak via the buzzer. / \u901a\u8fc7\u8702\u9e23\u5668\u63d0\u793a\u7528\u6237\u8bb2\u8bdd\u3002\nself\n.\npub_beep\n.\npublish\n(\nUInt16\n(\ndata\n=\n1\n))\ntime\n.\nsleep\n(\n0.5\n)\nself\n.\npub_beep\n.\npublish\n(\nUInt16\n(\ndata\n=\n0\n))\n\u200b\ntry\n:\n# Open audio stream. / \u6253\u5f00\u97f3\u9891\u6d41\u3002\nstream\n=\np\n.\nopen\n(\n**\nstream_kwargs\n)\nwhile\nTrue\n:\nif\nself\n.\nstop_event\n.\nis_set\n():\nreturn\nFalse\nframe\n=\nstream\n.\nread\n(\nself\n.\nframe_bytes\n,\nexception_on_overflow\n=\nFalse\n)\n# Read audio data. / \u8bfb\u53d6\u97f3\u9891\u6570\u636e\u3002\nis_speech\n=\nself\n.\nvad\n.\nis_speech\n(\nframe\n,\nself\n.\nsample_rate\n)\n# VAD detection. / VAD\u68c0\u6d4b\u3002\n\u200b\nif\nis_speech\n:\n# Detected speech activity. / \u68c0\u6d4b\u5230\u8bed\u97f3\u6d3b\u52a8\u3002\nspeaking\n=\nTrue\naudio_buffer\n.\nappend\n(\nframe\n)\nsilence_counter\n=\n0\nelse\n:\nif\nspeaking\n:\n# Detect silence after speech activity. / \u5728\u8bed\u97f3\u6d3b\u52a8\u540e\u68c0\u6d4b\u9759\u97f3\u3002\nsilence_counter\n+=\n1\naudio_buffer\n.\nappend\n(\nframe\n)\n# Continue recording buffer. / \u6301\u7eed\u8bb0\u5f55\u7f13\u51b2\u3002\n# End recording when silence duration meets the threshold. / \u9759\u97f3\u6301\u7eed\u65f6\u95f4\u8fbe\u6807\u65f6\u7ed3\u675f\u5f55\u97f3\u3002\nif\nsilence_counter\n>\n=\nMAX_SILENCE_FRAMES\n:\nbreak\nframe_counter\n+=\n1\nif\nframe_counter\n%\n2\n==\n0\n:\nself\n.\nget_logger\n().\ninfo\n(\n'1'\nif\nis_speech\nelse\n'-'\n)\n# Real-time status display.\nfinally\n:\nstream\n.\nstop_stream\n()\nstream\n.\nclose\n()\np\n.\nterminate\n()\n\u200b\n# Save valid recording (remove trailing silence). / \u4fdd\u5b58\u6709\u6548\u5f55\u97f3\uff08\u53bb\u9664\u5c3e\u90e8\u9759\u97f3\uff09\u3002\nif\nspeaking\nand\nlen\n(\naudio_buffer\n)\n>\n0\n:\n# Trim the last silent part. / \u88c1\u526a\u6700\u540e\u9759\u97f3\u90e8\u5206\u3002\nclean_buffer\n=\naudio_buffer\n[:\n-\nMAX_SILENCE_FRAMES\n]\nif\nlen\n(\naudio_buffer\n)\n>\nMAX_SILENCE_FRAMES\nelse\naudio_buffer\nwith\nwave\n.\nopen\n(\nself\n.\nuser_speechdir\n,\n'wb'\n)\nas\nwf\n:\nwf\n.\nsetnchannels\n(\n1\n)\nwf\n.\nsetsampwidth\n(\np\n.\nget_sample_size\n(\npyaudio\n.\npaInt16\n))\nwf\n.\nsetframerate\n(\nself\n.\nsample_rate\n)\nwf\n.\nwriteframes\n(\nb''\n.\njoin\n(\nclean_buffer\n))\nreturn\nTrue\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"xxxxxxxxxx\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"# From largemodel/largemodel/asr.py\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"def\nlisten_for_speech\n(\nself\n,\nmic_index\n=\n0\n):\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"p\n=\npyaudio\n.\nPyAudio\n()\n# Create PyAudio instance. / \u521b\u5efaPyAudio\u5b9e\u4f8b\u3002\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"audio_buffer\n= []\n# Store audio data. / \u5b58\u50a8\u97f3\u9891\u6570\u636e\u3002\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"silence_counter\n=\n0\n# Silence counter. / \u9759\u97f3\u8ba1\u6570\u5668\u3002\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"MAX_SILENCE_FRAMES\n=\n90\n# 30\u5e27*30ms=900ms\u9759\u97f3\u540e\u505c\u6b62 / Stop after 900ms of silence (30 frames * 30ms)\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"speaking\n=\nFalse\n# Flag indicating speech activity. / \u8bed\u97f3\u6d3b\u52a8\u6807\u5fd7\u3002\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"frame_counter\n=\n0\n# Frame counter. / \u8ba1\u6570\u5668\u3002\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"stream_kwargs\n= {\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"'format'\n:\npyaudio\n.\npaInt16\n,\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"'channels'\n:\n1\n,\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"'rate'\n:\nself\n.\nsample_rate\n,\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"'input'\n:\nTrue\n,\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"'frames_per_buffer'\n:\nself\n.\nframe_bytes\n,\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"}\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"if\nmic_index\n!\n=\n0\n:\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"stream_kwargs\n[\n'input_device_index'\n] =\nmic_index\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"\u200b\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"# Prompt the user to speak via the buzzer. / \u901a\u8fc7\u8702\u9e23\u5668\u63d0\u793a\u7528\u6237\u8bb2\u8bdd\u3002\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"self\n.\npub_beep\n.\npublish\n(\nUInt16\n(\ndata\n=\n1\n))\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"time\n.\nsleep\n(\n0.5\n)\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"self\n.\npub_beep\n.\npublish\n(\nUInt16\n(\ndata\n=\n0\n))\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"\u200b\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"try\n:\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"# Open audio stream. / \u6253\u5f00\u97f3\u9891\u6d41\u3002\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"stream\n=\np\n.\nopen\n(\n**\nstream_kwargs\n)\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"while\nTrue\n:\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"if\nself\n.\nstop_event\n.\nis_set\n():\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"return\nFalse\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"frame\n=\nstream\n.\nread\n(\nself\n.\nframe_bytes\n,\nexception_on_overflow\n=\nFalse\n)\n# Read audio data. / \u8bfb\u53d6\u97f3\u9891\u6570\u636e\u3002\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"is_speech\n=\nself\n.\nvad\n.\nis_speech\n(\nframe\n,\nself\n.\nsample_rate\n)\n# VAD detection. / VAD\u68c0\u6d4b\u3002\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"\u200b\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"if\nis_speech\n:\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"# Detected speech activity. / \u68c0\u6d4b\u5230\u8bed\u97f3\u6d3b\u52a8\u3002\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"speaking\n=\nTrue\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"audio_buffer\n.\nappend\n(\nframe\n)\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"silence_counter\n=\n0\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"else\n:\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"if\nspeaking\n:\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"# Detect silence after speech activity. / \u5728\u8bed\u97f3\u6d3b\u52a8\u540e\u68c0\u6d4b\u9759\u97f3\u3002\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"silence_counter\n+=\n1\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"audio_buffer\n.\nappend\n(\nframe\n)\n# Continue recording buffer. / \u6301\u7eed\u8bb0\u5f55\u7f13\u51b2\u3002\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"# End recording when silence duration meets the threshold. / \u9759\u97f3\u6301\u7eed\u65f6\u95f4\u8fbe\u6807\u65f6\u7ed3\u675f\u5f55\u97f3\u3002\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"if\nsilence_counter\n>\n=\nMAX_SILENCE_FRAMES\n:\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"break\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"frame_counter\n+=\n1\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"if\nframe_counter\n%\n2\n==\n0\n:\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"self\n.\nget_logger\n().\ninfo\n(\n'1'\nif\nis_speech\nelse\n'-'\n)\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"# Real-time status display.\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"finally\n:\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"stream\n.\nstop_stream\n()\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"stream\n.\nclose\n()\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"p\n.\nterminate\n()\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"\u200b\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"# Save valid recording (remove trailing silence). / \u4fdd\u5b58\u6709\u6548\u5f55\u97f3\uff08\u53bb\u9664\u5c3e\u90e8\u9759\u97f3\uff09\u3002\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"if\nspeaking\nand\nlen\n(\naudio_buffer\n)\n>\n0\n:\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"# Trim the last silent part. / \u88c1\u526a\u6700\u540e\u9759\u97f3\u90e8\u5206\u3002\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"clean_buffer\n=\naudio_buffer\n[:\n-\nMAX_SILENCE_FRAMES\n]\nif\nlen\n(\naudio_buffer\n)\n>\nMAX_SILENCE_FRAMES\nelse\naudio_buffer\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"with\nwave\n.\nopen\n(\nself\n.\nuser_speechdir\n,\n'wb'\n)\nas\nwf\n:\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"wf\n.\nsetnchannels\n(\n1\n)\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"wf\n.\nsetsampwidth\n(\np\n.\nget_sample_size\n(\npyaudio\n.\npaInt16\n))\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"wf\n.\nsetframerate\n(\nself\n.\nsample_rate\n)\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"wf\n.\nwriteframes\n(\nb''\n.\njoin\n(\nclean_buffer\n))\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"return\nTrue\n"})}),"\n",(0,l.jsx)(e.h3,{id:"code-analysis",children:"Code Analysis"}),"\n",(0,l.jsx)(e.p,{children:"ASR (speech-to-text) functionality is provided by the ASRNode node ( asr.py ). This node is responsible for recording, converting, and publishing audio."}),"\n",(0,l.jsx)(e.h2,{id:"3-practical-operations",children:"3. Practical Operations"}),"\n",(0,l.jsx)(e.h3,{id:"31-configuring-offline-asr",children:"3.1 Configuring Offline ASR"}),"\n",(0,l.jsx)(e.p,{children:"To enable offline ASR, you need to correctly configure the HemiHex.yaml file and ensure that the local model is correctly placed."}),"\n",(0,l.jsx)(e.p,{children:"Open the configuration file :"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"xxxxxxxxxx\nvim\n~/yahboom_ws/src/largemodel/config/HemiHex.yaml\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"xxxxxxxxxx\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"vim\n~/yahboom_ws/src/largemodel/config/HemiHex.yaml\n"})}),"\n",(0,l.jsx)(e.p,{children:"Modify/confirm the following key configuration :"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"xxxxxxxxxx\nasr\n:\n#Voice node parameters\nros__parameters\n:\n# ...\nuse_oline_asr\n:\nFalse\n# KEY: Must be set to False to enable offline ASR\nmic_serial_port\n:\n\"/dev/ttyUSB0\"\n# Microphone serial port alias\nmic_index\n:\n0\n# Microphone Device Index\nlanguage\n:\n'en'\n# asr language, 'zh' or 'en'\nregional_setting\n:\n\"international\"\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"xxxxxxxxxx\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"asr\n:\n#Voice node parameters\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"ros__parameters\n:\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"# ...\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"use_oline_asr\n:\nFalse\n# KEY: Must be set to False to enable offline ASR\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:'mic_serial_port\n:\n"/dev/ttyUSB0"\n# Microphone serial port alias\n'})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"mic_index\n:\n0\n# Microphone Device Index\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"language\n:\n'en'\n# asr language, 'zh' or 'en'\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:'regional_setting\n:\n"international"\n'})}),"\n",(0,l.jsx)(e.p,{children:"Make sure use_oline_asr is set to False to use the local model."}),"\n",(0,l.jsx)(e.p,{children:"In the terminal, enter ls /dev/ttyUSB* to check if the USB device number assigned to the voice module is USB0. If not, replace the 0 in the configuration file with your desired device number."}),"\n",(0,l.jsx)(e.p,{children:'Select "zh" for Chinese and "en" for English.'}),"\n",(0,l.jsx)(e.p,{children:"Also, specify the path to the offline model in large_model_interface.yaml ."}),"\n",(0,l.jsx)(e.p,{children:"Open the file in the terminal:"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"xxxxxxxxxx\nvim ~/yahboom_ws/src/largemodel/config/large_model_interface.yaml\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"xxxxxxxxxx\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"vim ~/yahboom_ws/src/largemodel/config/large_model_interface.yaml\n"})}),"\n",(0,l.jsx)(e.p,{children:"Find the configuration related to local_asr_model ."}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:'xxxxxxxxxx\n# large_model_interface.yaml\n## \u79bb\u7ebf\u8bed\u97f3\u8bc6\u522b (Offline ASR)\nlocal_asr_model\n:\n"/home/jetson/yahboom_ws/src/largemodel/MODELS/asr/SenseVoiceSmall"\n# Local ASR model path\n'})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"xxxxxxxxxx\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"# large_model_interface.yaml\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"## \u79bb\u7ebf\u8bed\u97f3\u8bc6\u522b (Offline ASR)\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:'local_asr_model\n:\n"/home/jetson/yahboom_ws/src/largemodel/MODELS/asr/SenseVoiceSmall"\n# Local ASR model path\n'})}),"\n",(0,l.jsx)(e.h3,{id:"32-start-and-test-the-functionality",children:"3.2 Start and test the functionality"}),"\n",(0,l.jsx)(e.p,{children:"Startup Command :"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"xxxxxxxxxx\nros2 launch largemodel asr_only.launch.py\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"xxxxxxxxxx\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"ros2 launch largemodel asr_only.launch.py\n"})}),"\n",(0,l.jsx)(e.p,{children:(0,l.jsx)(e.img,{alt:"image-20250807154240917",src:s(85946).A+"",width:"901",height:"120"})})]})}function h(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,l.jsx)(e,{...n,children:(0,l.jsx)(d,{...n})}):d(n)}},85946:(n,e,s)=>{s.d(e,{A:()=>a});const a=s.p+"assets/images/1-dac20ccff5c2847f8a09afc4e4121f65.png"}}]);