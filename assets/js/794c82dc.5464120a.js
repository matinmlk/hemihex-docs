"use strict";(globalThis.webpackChunkhemihex_docs=globalThis.webpackChunkhemihex_docs||[]).push([[1437],{28453:(e,n,a)=>{a.d(n,{R:()=>r,x:()=>i});var s=a(96540);const l={},t=s.createContext(l);function r(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:r(e.components),s.createElement(t.Provider,{value:n},e.children)}},32955:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>o,contentTitle:()=>i,default:()=>h,frontMatter:()=>r,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"HH-101/Offline AI Model/multimodal-autonomous-agent-application-11-offlineaimodel-11-16","title":"Multimodal Autonomous Agent Application","description":"1. Concept Introduction","source":"@site/docs/hh101/HH-101/11- Offline AI Model/16-multimodal-autonomous-agent-application-11-offlineaimodel-11-16.md","sourceDirName":"HH-101/11- Offline AI Model","slug":"/HH-101/Offline AI Model/multimodal-autonomous-agent-application-11-offlineaimodel-11-16","permalink":"/hh-101/HH-101/Offline AI Model/multimodal-autonomous-agent-application-11-offlineaimodel-11-16","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":0,"frontMatter":{"title":"Multimodal Autonomous Agent Application","sidebar_position":0},"sidebar":"hh101Sidebar","previous":{"title":"Multimodal Table Scanning Application","permalink":"/hh-101/HH-101/Offline AI Model/multimodal-table-scanning-application-11-offlineaimodel-11-15"},"next":{"title":"Voice Interaction Hardware Connection","permalink":"/hh-101/HH-101/Offline AI Model/voice-interaction-hardware-connection-11-offlineaimodel-11-17"}}');var l=a(74848),t=a(28453);const r={title:"Multimodal Autonomous Agent Application",sidebar_position:0},i="Multimodal autonomous agent application",o={},c=[{value:"1. Concept Introduction",id:"1-concept-introduction",level:2},{value:"1.1 What is an &quot;Autonomous Agent&quot;?",id:"11-what-is-an-autonomous-agent",level:3},{value:"1.2 Implementation Principles",id:"12-implementation-principles",level:3},{value:"2. Code Analysis",id:"2-code-analysis",level:2},{value:"Key Code",id:"key-code",level:3},{value:"1. Agent Core Workflow ( largemodel/utils/ai_agent.py )",id:"1-agent-core-workflow--largemodelutilsai_agentpy-",level:4},{value:"2. Mission planning and LLM interaction ( largemodel/utils/ai_agent.py )",id:"2-mission-planning-and-llm-interaction--largemodelutilsai_agentpy-",level:4},{value:"3. Parameter processing and data flow implementation ( largemodel/utils/ai_agent.py )",id:"3-parameter-processing-and-data-flow-implementation--largemodelutilsai_agentpy-",level:4},{value:"Code Analysis",id:"code-analysis",level:3},{value:"3. Practical Operations",id:"3-practical-operations",level:2},{value:"3.1 Configuring the Offline Large Model",id:"31-configuring-the-offline-large-model",level:3},{value:"3.1.1 Configuring the LLM Platform ( HemiHex.yaml )",id:"311-configuring-the-llm-platform--hemihexyaml-",level:4},{value:"3.1.2 Configuration model interface ( large_model_interface.yaml )",id:"312-configuration-model-interface--large_model_interfaceyaml-",level:4},{value:"3.2 Starting and Testing the Functionality (Text Input Mode)",id:"32-starting-and-testing-the-functionality-text-input-mode",level:3},{value:"4. Common Problems and Solutions",id:"4-common-problems-and-solutions",level:2},{value:"4.1 Abnormal Agent Behavior",id:"41-abnormal-agent-behavior",level:3},{value:"Issue 1: The agent is stuck in an infinite loop or repeatedly executing the same tool.",id:"issue-1-the-agent-is-stuck-in-an-infinite-loop-or-repeatedly-executing-the-same-tool",level:4},{value:"4.2 Tool Invocation Failure",id:"42-tool-invocation-failure",level:3},{value:"Issue 2: The agent correctly planned the action, but the tool execution failed.",id:"issue-2-the-agent-correctly-planned-the-action-but-the-tool-execution-failed",level:4}];function d(e){const n={admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",p:"p",pre:"pre",...(0,t.R)(),...e.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(n.header,{children:(0,l.jsx)(n.h1,{id:"multimodal-autonomous-agent-application",children:"Multimodal autonomous agent application"})}),"\n",(0,l.jsx)(n.h2,{id:"1-concept-introduction",children:"1. Concept Introduction"}),"\n",(0,l.jsx)(n.h3,{id:"11-what-is-an-autonomous-agent",children:'1.1 What is an "Autonomous Agent"?'}),"\n",(0,l.jsx)(n.p,{children:"In the largemodel project, multimodal autonomous agents represent the most advanced form of intelligence. Rather than simply responding to a user's command, they are capable of autonomously thinking, planning, and continuously invoking multiple tools to achieve a complex goal ."}),"\n",(0,l.jsx)(n.p,{children:"The core of this functionality is the **agent_call ** tool or its underlying **ToolChainManager . When a user issues a complex request that cannot be accomplished with a single tool call, the autonomous agent is activated."}),"\n",(0,l.jsx)(n.h3,{id:"12-implementation-principles",children:"1.2 Implementation Principles"}),"\n",(0,l.jsx)(n.p,{children:'The autonomous agent implementation in largemodel follows the industry-leading ReAct (Reason + Act) paradigm. Its core concept is to mimic the human problem-solving process, cycling between "thinking" and "acting."'}),"\n",(0,l.jsx)(n.p,{children:"This think -> act -> observe cycle continues until the initial goal is achieved, at which point the agent generates and outputs the final answer."}),"\n",(0,l.jsx)(n.h2,{id:"2-code-analysis",children:"2. Code Analysis"}),"\n",(0,l.jsx)(n.h3,{id:"key-code",children:"Key Code"}),"\n",(0,l.jsx)(n.h4,{id:"1-agent-core-workflow--largemodelutilsai_agentpy-",children:"1. Agent Core Workflow ( largemodel/utils/ai_agent.py )"}),"\n",(0,l.jsx)(n.p,{children:'The _execute_agent_workflow function is the agent\'s main execution loop, defining the core "plan -> execute" process.'}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'xxxxxxxxxx\n# From largemodel/utils/ai_agent.py\n\u200b\nclass\nAIAgent\n:\n# ...\n\u200b\ndef\n_execute_agent_workflow\n(\nself\n,\ntask_description\n:\nstr\n)\n->\nDict\n[\nstr\n,\nAny\n]:\n"""\nExecutes the agent workflow: Plan -> Execute. / \u6267\u884cAgent\u5de5\u4f5c\u6d41\uff1a\u89c4\u5212 -> \u6267\u884c\u3002\n"""\ntry\n:\n# Step 1: Mission Planning\nself\n.\nnode\n.\nget_logger\n().\ninfo\n(\n"AI Agent starting task planning phase"\n)\nplan_result\n=\nself\n.\n_plan_task\n(\ntask_description\n)\n# ... (Return early if planning fails)\n\u200b\nself\n.\ntask_steps\n=\nplan_result\n[\n"steps"\n]\n\u200b\n# Step 2: Follow all steps in order\nexecution_results\n= []\ntool_outputs\n= []\n\u200b\nfor\ni\n,\nstep\nin\nenumerate\n(\nself\n.\ntask_steps\n):\n# 2.1. Processing data references in parameters before execution\nprocessed_parameters\n=\nself\n.\n_process_step_parameters\n(\nstep\n.\nget\n(\n"parameters"\n, {}),\ntool_outputs\n)\nstep\n[\n"parameters"\n] =\nprocessed_parameters\n\u200b\n# 2.2. Executing a single step\nstep_result\n=\nself\n.\n_execute_step\n(\nstep\n,\ntool_outputs\n)\nexecution_results\n.\nappend\n(\nstep_result\n)\n\u200b\n# 2.3. If the step succeeds, save its output for reference in subsequent steps\nif\nstep_result\n.\nget\n(\n"success"\n)\nand\nstep_result\n.\nget\n(\n"tool_output"\n):\ntool_outputs\n.\nappend\n(\nstep_result\n[\n"tool_output"\n])\nelse\n:\n# If any step fails, abort the entire task\nreturn\n{\n"success"\n:\nFalse\n,\n"message"\n:\nf"Task terminated because step \'{step[\'description\']}\' failed."\n}\n# ... Summarize and return the final result\nsummary\n=\nself\n.\n_summarize_execution\n(\ntask_description\n,\nexecution_results\n)\nreturn\n{\n"success"\n:\nTrue\n,\n"message"\n:\nsummary\n,\n"results"\n:\nexecution_results\n}\n\u200b\n# ... (Exception handling)\n'})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"xxxxxxxxxx\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"# From largemodel/utils/ai_agent.py\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"class\nAIAgent\n:\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"# ...\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"def\n_execute_agent_workflow\n(\nself\n,\ntask_description\n:\nstr\n)\n->\nDict\n[\nstr\n,\nAny\n]:\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'"""\n'})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"Executes the agent workflow: Plan -> Execute. / \u6267\u884cAgent\u5de5\u4f5c\u6d41\uff1a\u89c4\u5212 -> \u6267\u884c\u3002\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'"""\n'})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"try\n:\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"# Step 1: Mission Planning\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'self\n.\nnode\n.\nget_logger\n().\ninfo\n(\n"AI Agent starting task planning phase"\n)\n'})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"plan_result\n=\nself\n.\n_plan_task\n(\ntask_description\n)\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"# ... (Return early if planning fails)\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'self\n.\ntask_steps\n=\nplan_result\n[\n"steps"\n]\n'})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"# Step 2: Follow all steps in order\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"execution_results\n= []\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"tool_outputs\n= []\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"for\ni\n,\nstep\nin\nenumerate\n(\nself\n.\ntask_steps\n):\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"# 2.1. Processing data references in parameters before execution\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'processed_parameters\n=\nself\n.\n_process_step_parameters\n(\nstep\n.\nget\n(\n"parameters"\n, {}),\ntool_outputs\n)\n'})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'step\n[\n"parameters"\n] =\nprocessed_parameters\n'})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"# 2.2. Executing a single step\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"step_result\n=\nself\n.\n_execute_step\n(\nstep\n,\ntool_outputs\n)\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"execution_results\n.\nappend\n(\nstep_result\n)\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"# 2.3. If the step succeeds, save its output for reference in subsequent steps\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'if\nstep_result\n.\nget\n(\n"success"\n)\nand\nstep_result\n.\nget\n(\n"tool_output"\n):\n'})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'tool_outputs\n.\nappend\n(\nstep_result\n[\n"tool_output"\n])\n'})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"else\n:\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"# If any step fails, abort the entire task\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'return\n{\n"success"\n:\nFalse\n,\n"message"\n:\nf"Task terminated because step \'{step[\'description\']}\' failed."\n}\n'})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"# ... Summarize and return the final result\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"summary\n=\nself\n.\n_summarize_execution\n(\ntask_description\n,\nexecution_results\n)\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'return\n{\n"success"\n:\nTrue\n,\n"message"\n:\nsummary\n,\n"results"\n:\nexecution_results\n}\n'})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"# ... (Exception handling)\n"})}),"\n",(0,l.jsx)(n.h4,{id:"2-mission-planning-and-llm-interaction--largemodelutilsai_agentpy-",children:"2. Mission planning and LLM interaction ( largemodel/utils/ai_agent.py )"}),"\n",(0,l.jsx)(n.p,{children:"The core of the _plan_task function is to build a sophisticated prompt and use the reasoning ability of the large model to generate a structured execution plan."}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'xxxxxxxxxx\n# From largemodel/utils/ai_agent.py\n\u200b\nclass\nAIAgent\n:\n# ...\ndef\n_plan_task\n(\nself\n,\ntask_description\n:\nstr\n)\n->\nDict\n[\nstr\n,\nAny\n]:\n"""\nUses the large model for task planning and decomposition. / \u4f7f\u7528\u5927\u6a21\u578b\u8fdb\u884c\u4efb\u52a1\u89c4\u5212\u548c\u5206\u89e3\u3002\n"""\n# Dynamically generate a list of available tools and their descriptions\ntool_descriptions\n= []\nfor\nname\n,\nadapter\nin\nself\n.\ntools_manager\n.\ntool_chain_manager\n.\ntools\n.\nitems\n():\n# ... (Get tool description from adapter.input_schema)\ntool_descriptions\n.\nappend\n(\nf"- {name}({params}): {description}"\n)\navailable_tools_str\n=\n"\\\\n"\n.\njoin\n(\ntool_descriptions\n)\n\u200b\n# Build a highly structured plan\nplanning_prompt\n=\nf"""\nAs a professional task planning Agent, please break down the user\'s task into a series of specific, executable JSON steps.\n\u200b\n**# Available Tools:**\n{available_tools_str}\n\u200b\n**# Core Rules:**\n1.  **Data Passing**: When a subsequent step needs to use the output of a previous step, you **must** use the `{{{{steps.N.outputs.KEY}}}}` format for referencing.\n- `N` is the step ID (starting from 1).\n- `KEY` is the specific field name in the output data of the previous step.\n- `outputs` can be followed by `data` (for primary data) or `metadata.sub_key` (for metadata).\n2.  **JSON Format**: You must strictly return a JSON object. Do not include any Markdown wrappers (like ```json```).\n3.  **Tool Selection**: Strictly select the most appropriate tool based on its description.\n\u200b\n**#  User Task:**\n{task_description}\n"""\n# Calling large models for planning\nmessages_to_use\n= [{\n"role"\n:\n"user"\n,\n"content"\n:\nplanning_prompt\n}]\n# Note that the general text reasoning interface is called here\nresult\n=\nself\n.\nnode\n.\nmodel_client\n.\ninfer_with_text\n(\n""\n,\nmessage\n=\nmessages_to_use\n)\n# ... (Parse the JSON response and return a list of steps)\n'})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"xxxxxxxxxx\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"# From largemodel/utils/ai_agent.py\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"class\nAIAgent\n:\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"# ...\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"def\n_plan_task\n(\nself\n,\ntask_description\n:\nstr\n)\n->\nDict\n[\nstr\n,\nAny\n]:\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'"""\n'})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"Uses the large model for task planning and decomposition. / \u4f7f\u7528\u5927\u6a21\u578b\u8fdb\u884c\u4efb\u52a1\u89c4\u5212\u548c\u5206\u89e3\u3002\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'"""\n'})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"# Dynamically generate a list of available tools and their descriptions\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"tool_descriptions\n= []\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"for\nname\n,\nadapter\nin\nself\n.\ntools_manager\n.\ntool_chain_manager\n.\ntools\n.\nitems\n():\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"# ... (Get tool description from adapter.input_schema)\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'tool_descriptions\n.\nappend\n(\nf"- {name}({params}): {description}"\n)\n'})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'available_tools_str\n=\n"\\\\n"\n.\njoin\n(\ntool_descriptions\n)\n'})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"# Build a highly structured plan\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'planning_prompt\n=\nf"""\n'})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"As a professional task planning Agent, please break down the user's task into a series of specific, executable JSON steps.\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"**# Available Tools:**\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"{available_tools_str}\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"**# Core Rules:**\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"1.  **Data Passing**: When a subsequent step needs to use the output of a previous step, you **must** use the `{{{{steps.N.outputs.KEY}}}}` format for referencing.\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"- `N` is the step ID (starting from 1).\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"- `KEY` is the specific field name in the output data of the previous step.\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"- `outputs` can be followed by `data` (for primary data) or `metadata.sub_key` (for metadata).\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"2.  **JSON Format**: You must strictly return a JSON object. Do not include any Markdown wrappers (like ```json```).\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"3.  **Tool Selection**: Strictly select the most appropriate tool based on its description.\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"**#  User Task:**\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"{task_description}\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'"""\n'})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"# Calling large models for planning\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'messages_to_use\n= [{\n"role"\n:\n"user"\n,\n"content"\n:\nplanning_prompt\n}]\n'})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"# Note that the general text reasoning interface is called here\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'result\n=\nself\n.\nnode\n.\nmodel_client\n.\ninfer_with_text\n(\n""\n,\nmessage\n=\nmessages_to_use\n)\n'})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"# ... (Parse the JSON response and return a list of steps)\n"})}),"\n",(0,l.jsx)(n.h4,{id:"3-parameter-processing-and-data-flow-implementation--largemodelutilsai_agentpy-",children:"3. Parameter processing and data flow implementation ( largemodel/utils/ai_agent.py )"}),"\n",(0,l.jsx)(n.p,{children:"The _process_step_parameters function is responsible for parsing placeholders and implementing data flow between steps."}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'xxxxxxxxxx\n# From largemodel/utils/ai_agent.py\n\u200b\nclass\nAIAgent\n:\n# ...\ndef\n_process_step_parameters\n(\nself\n,\nparameters\n:\nDict\n[\nstr\n,\nAny\n],\nprevious_outputs\n:\nList\n[\nAny\n])\n->\nDict\n[\nstr\n,\nAny\n]:\n"""\nParses parameter dictionary, finds and replaces all {{...}} references.\n"""\nprocessed_params\n=\nparameters\n.\ncopy\n()\n# Regular expression used to match placeholders in the format {{steps.N.outputs.KEY}}\npattern\n=\nre\n.\ncompile\n(\nr"\\\\{\\\\{steps\\\\.(\\\\d+)\\\\.outputs\\\\.(.+?)\\\\}\\\\}"\n)\n\u200b\nfor\nkey\n,\nvalue\nin\nprocessed_params\n.\nitems\n():\nif\nisinstance\n(\nvalue\n,\nstr\n)\nand\npattern\n.\nsearch\n(\nvalue\n):\n# Use re.sub and a replacement function to process all found placeholders.\n# The replacement function will look up and return the value from the previous_outputs list.\nprocessed_params\n[\nkey\n] =\npattern\n.\nsub\n(\nreplacer_function\n,\nvalue\n)\nreturn\nprocessed_params\n'})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"xxxxxxxxxx\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"# From largemodel/utils/ai_agent.py\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"class\nAIAgent\n:\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"# ...\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"def\n_process_step_parameters\n(\nself\n,\nparameters\n:\nDict\n[\nstr\n,\nAny\n],\nprevious_outputs\n:\nList\n[\nAny\n])\n->\nDict\n[\nstr\n,\nAny\n]:\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'"""\n'})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"Parses parameter dictionary, finds and replaces all {{...}} references.\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'"""\n'})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"processed_params\n=\nparameters\n.\ncopy\n()\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"# Regular expression used to match placeholders in the format {{steps.N.outputs.KEY}}\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'pattern\n=\nre\n.\ncompile\n(\nr"\\\\{\\\\{steps\\\\.(\\\\d+)\\\\.outputs\\\\.(.+?)\\\\}\\\\}"\n)\n'})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"for\nkey\n,\nvalue\nin\nprocessed_params\n.\nitems\n():\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"if\nisinstance\n(\nvalue\n,\nstr\n)\nand\npattern\n.\nsearch\n(\nvalue\n):\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"# Use re.sub and a replacement function to process all found placeholders.\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"# The replacement function will look up and return the value from the previous_outputs list.\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"processed_params\n[\nkey\n] =\npattern\n.\nsub\n(\nreplacer_function\n,\nvalue\n)\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"return\nprocessed_params\n"})}),"\n",(0,l.jsx)(n.h3,{id:"code-analysis",children:"Code Analysis"}),"\n",(0,l.jsx)(n.p,{children:'The AI \u200b\u200bAgent is the "brain" of the system, translating high-level, sometimes ambiguous, tasks posed by the user into a precise, ordered series of tool calls. Its implementation is independent of any specific model platform and built on a general, extensible architecture.'}),"\n",(0,l.jsx)(n.p,{children:"In summary, the general implementation of the AI \u200b\u200bAgent demonstrates an advanced software architecture: rather than solving a problem directly, it builds a framework that enables an external, general-purpose reasoning engine (a large model) to solve the problem. Through two core mechanisms, dynamic programming and data flow management, the Agent orchestrates a series of independent tools into complex workflows capable of completing advanced tasks."}),"\n",(0,l.jsx)(n.h2,{id:"3-practical-operations",children:"3. Practical Operations"}),"\n",(0,l.jsx)(n.h3,{id:"31-configuring-the-offline-large-model",children:"3.1 Configuring the Offline Large Model"}),"\n",(0,l.jsx)(n.h4,{id:"311-configuring-the-llm-platform--hemihexyaml-",children:"3.1.1 Configuring the LLM Platform ( HemiHex.yaml )"}),"\n",(0,l.jsx)(n.p,{children:"This file determines which large model platform the model_service node loads as its primary language model."}),"\n",(0,l.jsx)(n.p,{children:"Open the file in the terminal :"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"xxxxxxxxxx\nvim\n~/yahboom_ws/src/largemodel/config/HemiHex.yaml\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"xxxxxxxxxx\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"vim\n~/yahboom_ws/src/largemodel/config/HemiHex.yaml\n"})}),"\n",(0,l.jsx)(n.p,{children:"Modify/confirm llm_platform :"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"xxxxxxxxxx\nmodel_service\n:\n#\u6a21\u578b\u670d\u52a1\u5668\u8282\u70b9\u53c2\u6570 Model server node parameters\nros__parameters\n:\nlanguage\n:\n'en'\n#\u5927\u6a21\u578b\u63a5\u53e3\u8bed\u8a00 Large Model Interface Language\nuseolinetts\n:\nFalse\n#\u6587\u5b57\u6a21\u5f0f\u4e0b\u6b64\u9879\u65e0\u6548\uff0c\u53ef\u5ffd\u7565 This item is invalid in text mode and can be ignored\n\u200b\n# \u5927\u6a21\u578b\u914d\u7f6e Large model configuration\nllm_platform\n:\n'ollama'\n# \u5173\u952e: \u786e\u4fdd\u8fd9\u91cc\u662f 'ollama' Key: Make sure it's 'ollama'\nregional_setting\n:\n\"international\"\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"xxxxxxxxxx\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"model_service\n:\n#\u6a21\u578b\u670d\u52a1\u5668\u8282\u70b9\u53c2\u6570 Model server node parameters\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"ros__parameters\n:\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"language\n:\n'en'\n#\u5927\u6a21\u578b\u63a5\u53e3\u8bed\u8a00 Large Model Interface Language\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"useolinetts\n:\nFalse\n#\u6587\u5b57\u6a21\u5f0f\u4e0b\u6b64\u9879\u65e0\u6548\uff0c\u53ef\u5ffd\u7565 This item is invalid in text mode and can be ignored\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"# \u5927\u6a21\u578b\u914d\u7f6e Large model configuration\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"llm_platform\n:\n'ollama'\n# \u5173\u952e: \u786e\u4fdd\u8fd9\u91cc\u662f 'ollama' Key: Make sure it's 'ollama'\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'regional_setting\n:\n"international"\n'})}),"\n",(0,l.jsx)(n.h4,{id:"312-configuration-model-interface--large_model_interfaceyaml-",children:"3.1.2 Configuration model interface ( large_model_interface.yaml )"}),"\n",(0,l.jsx)(n.p,{children:"This file defines which visual model to use when the platform is selected as ollama ."}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"xxxxxxxxxx\nvim ~/yahboom_ws/src/largemodel/config/large_model_interface.yaml\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"xxxxxxxxxx\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"vim ~/yahboom_ws/src/largemodel/config/large_model_interface.yaml\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'xxxxxxxxxx\n#.....\n## \u79bb\u7ebf\u5927\u6a21\u578b (Offline Large Language Models)\n# Ollama Configuration\nollama_host:\n"http://localhost:11434"\n# Ollama server address\nollama_model:\n"llava"\n# Key: Change this to the multimodal model you downloaded, such as "llava"\n#.....\n'})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"xxxxxxxxxx\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"#.....\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"## \u79bb\u7ebf\u5927\u6a21\u578b (Offline Large Language Models)\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"# Ollama Configuration\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'ollama_host:\n"http://localhost:11434"\n# Ollama server address\n'})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'ollama_model:\n"llava"\n# Key: Change this to the multimodal model you downloaded, such as "llava"\n'})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"#.....\n"})}),"\n",(0,l.jsx)(n.p,{children:"Note : Please ensure that the model specified in the configuration parameters (e.g., llava ) can handle multimodal input."}),"\n",(0,l.jsx)(n.h3,{id:"32-starting-and-testing-the-functionality-text-input-mode",children:"3.2 Starting and Testing the Functionality (Text Input Mode)"}),"\n",(0,l.jsx)(n.admonition,{type:"warning",children:(0,l.jsx)(n.p,{children:'Due to performance limitations, the performance of the Jetson Orin Nano 4GB is limited. To experience this feature, please refer to the "Online Large Model (Text Interaction)" section.'})}),"\n",(0,l.jsx)(n.p,{children:"Start the largemodel main program (text mode): Open a terminal and run the following command:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"xxxxxxxxxx\nros2 launch largemodel largemodel_control.launch.py text_chat_mode:\n=\ntrue\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"xxxxxxxxxx\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"ros2 launch largemodel largemodel_control.launch.py text_chat_mode:\n=\ntrue\n"})}),"\n",(0,l.jsx)(n.p,{children:"Send text command : Open another terminal and run the following command:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"xxxxxxxxxx\nros2 run text_chat text_chat\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"xxxxxxxxxx\n"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"ros2 run text_chat text_chat\n"})}),"\n",(0,l.jsx)(n.p,{children:'Then start entering text: "Based on the current environment, save the generated environment description as a txt document."'}),"\n",(0,l.jsx)(n.p,{children:"Observe the Results :"}),"\n",(0,l.jsx)(n.p,{children:"In the first terminal running the main program, you will see log output indicating that the system receives the text command, invokes the aiagent tool, and then provides a prompt to LLM. LLM will analyze the detailed steps of the tool invocation. For example, in this question, the seewhat tool will be invoked to capture the image, which will then be parsed by LLM. The parsed text will be saved in the ~/yahboom_ws/src/largemodel/resources_file/documents folder."}),"\n",(0,l.jsx)(n.h2,{id:"4-common-problems-and-solutions",children:"4. Common Problems and Solutions"}),"\n",(0,l.jsx)(n.h3,{id:"41-abnormal-agent-behavior",children:"4.1 Abnormal Agent Behavior"}),"\n",(0,l.jsx)(n.h4,{id:"issue-1-the-agent-is-stuck-in-an-infinite-loop-or-repeatedly-executing-the-same-tool",children:"Issue 1: The agent is stuck in an infinite loop or repeatedly executing the same tool."}),"\n",(0,l.jsx)(n.p,{children:"Solution :"}),"\n",(0,l.jsx)(n.h3,{id:"42-tool-invocation-failure",children:"4.2 Tool Invocation Failure"}),"\n",(0,l.jsx)(n.h4,{id:"issue-2-the-agent-correctly-planned-the-action-but-the-tool-execution-failed",children:"Issue 2: The agent correctly planned the action, but the tool execution failed."}),"\n",(0,l.jsx)(n.p,{children:"Solution :"})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,l.jsx)(n,{...e,children:(0,l.jsx)(d,{...e})}):d(e)}}}]);