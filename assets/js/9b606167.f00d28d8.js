"use strict";(globalThis.webpackChunkhemihex_docs=globalThis.webpackChunkhemihex_docs||[]).push([[1214],{14206:(e,n,i)=>{i.d(n,{A:()=>a});const a=i.p+"assets/images/89dc5a19-179e-4dd3-8e5d-12ad54973148-22d7a18cdf39d33602b43599bf6fe6c6.png"},28453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>r});var a=i(96540);const s={},t=a.createContext(s);function l(e){const n=a.useContext(t);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),a.createElement(t.Provider,{value:n},e.children)}},35303:(e,n,i)=>{i.d(n,{A:()=>a});const a=i.p+"assets/images/test_pic-e0ed5b2c9cb2ab81f2f173147ab582de.png"},36838:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>r,default:()=>h,frontMatter:()=>l,metadata:()=>a,toc:()=>d});const a=JSON.parse('{"id":"HH-101/Offline AI Model/gemma3-11-offlineaimodel-11-8","title":"Gemma3","description":"Demo Environment","source":"@site/docs/hh101/HH-101/11- Offline AI Model/08-gemma3-11-offlineaimodel-11-8.md","sourceDirName":"HH-101/11- Offline AI Model","slug":"/HH-101/Offline AI Model/gemma3-11-offlineaimodel-11-8","permalink":"/hh-101/HH-101/Offline AI Model/gemma3-11-offlineaimodel-11-8","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":0,"frontMatter":{"title":"Gemma3","sidebar_position":0},"sidebar":"hh101Sidebar","previous":{"title":"Qwen2.5VL","permalink":"/hh-101/HH-101/Offline AI Model/qwen2-5vl-11-offlineaimodel-11-7"},"next":{"title":"Llava","permalink":"/hh-101/HH-101/Offline AI Model/llava-11-offlineaimodel-11-9"}}');var s=i(74848),t=i(28453);const l={title:"Gemma3",sidebar_position:0},r="Gemma3",o={},d=[{value:"1. Model Size",id:"1-model-size",level:2},{value:"2. Performance",id:"2-performance",level:2},{value:"3. Using Gemma3",id:"3-using-gemma3",level:2},{value:"3.1 Running Gemma3",id:"31-running-gemma3",level:3},{value:"3.2 Start a conversation",id:"32-start-a-conversation",level:3},{value:"3.3 Visual Function",id:"33-visual-function",level:3},{value:"3.4 Ending the Conversation",id:"34-ending-the-conversation",level:3},{value:"References",id:"references",level:2}];function c(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"gemma3",children:"Gemma3"})}),"\n",(0,s.jsx)(n.admonition,{type:"note",children:(0,s.jsx)(n.p,{children:"Demo Environment"})}),"\n",(0,s.jsx)(n.p,{children:"Demo Environment"}),"\n",(0,s.jsx)(n.p,{children:"Development Board : Jetson Orin series motherboard"}),"\n",(0,s.jsx)(n.admonition,{type:"warning",children:(0,s.jsx)(n.p,{children:"Due to performance limitations, the Jetson Orin Nano 4GB requires the reduced-parameter version"})}),"\n",(0,s.jsx)(n.p,{children:"Gemma is a family of lightweight models built by Google based on Gemini technology. The Gemma 3 model is multimodal (capable of processing text and images), has a 128KB context window, and supports over 140 languages."}),"\n",(0,s.jsx)(n.h2,{id:"1-model-size",children:"1. Model Size"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Model"}),(0,s.jsx)(n.th,{children:"Size"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"gemma3:1b"}),(0,s.jsx)(n.td,{children:"815MB"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"gemma3:4b"}),(0,s.jsx)(n.td,{children:"3.3GB"})]})]})]}),"\n",(0,s.jsx)(n.h2,{id:"2-performance",children:"2. Performance"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Chatbot Arena ELO Score",src:i(14206).A+"",width:"2284",height:"1444"})}),"\n",(0,s.jsx)(n.h2,{id:"3-using-gemma3",children:"3. Using Gemma3"}),"\n",(0,s.jsx)(n.h3,{id:"31-running-gemma3",children:"3.1 Running Gemma3"}),"\n",(0,s.jsx)(n.p,{children:"Use the run command to run the model. If the model is not already downloaded, it will automatically pull the model from the Ollama model library:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"ollama run gemma3:4b\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"xxxxxxxxxx\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"ollama run gemma3:4b\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Screenshot",src:i(59349).A+"",width:"496",height:"197"})}),"\n",(0,s.jsx)(n.h3,{id:"32-start-a-conversation",children:"3.2 Start a conversation"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"How to learn a programming language?\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"xxxxxxxxxx\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"How to learn a programming language?\n"})}),"\n",(0,s.jsx)(n.p,{children:"Response time depends on hardware configuration, so please be patient!"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Screenshot",src:i(74959).A+"",width:"676",height:"426"})}),"\n",(0,s.jsx)(n.h3,{id:"33-visual-function",children:"3.3 Visual Function"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"test_pic",src:i(35303).A+"",width:"1334",height:"750"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'What do you see in this picture? :./test_pic.png\n#Using ": + the image path" in the conversation allows the model to use its visual function and interpret the information in the image.\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"xxxxxxxxxx\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"What do you see in this picture? :./test_pic.png\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'#Using ": + the image path" in the conversation allows the model to use its visual function and interpret the information in the image.\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Screenshot",src:i(61287).A+"",width:"676",height:"358"})}),"\n",(0,s.jsx)(n.h3,{id:"34-ending-the-conversation",children:"3.4 Ending the Conversation"}),"\n",(0,s.jsx)(n.p,{children:"Use the Ctrl+d shortcut or /bye to end the conversation!"}),"\n",(0,s.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Ollama"}),"\nOllama"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Official Website"}),": ",(0,s.jsx)(n.a,{href:"https://ollama.com/",children:"https://ollama.com/"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"GitHub"}),": ",(0,s.jsx)(n.a,{href:"https://github.com/ollama/ollama",children:"https://github.com/ollama/ollama"}),"\n",(0,s.jsx)(n.strong,{children:"Gemma3"}),"\nGemma3"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Ollama Compatible Model"}),": ",(0,s.jsx)(n.a,{href:"https://ollama.com/library/gemma3",children:"https://ollama.com/library/gemma3"})]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},59349:(e,n,i)=>{i.d(n,{A:()=>a});const a=i.p+"assets/images/1-b36ba45d17d36b72196f6816b389c4fe.png"},61287:(e,n,i)=>{i.d(n,{A:()=>a});const a=i.p+"assets/images/3-8bff986e641bf03b9a1286e135c27309.png"},74959:(e,n,i)=>{i.d(n,{A:()=>a});const a=i.p+"assets/images/image-20250630115641821-446df37c9e8d0cc9b329a41ae3a3b73e.png"}}]);