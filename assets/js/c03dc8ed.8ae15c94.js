"use strict";(globalThis.webpackChunkhemihex_docs=globalThis.webpackChunkhemihex_docs||[]).push([[5393],{6351:(e,s,a)=>{a.d(s,{A:()=>n});const n=a.p+"assets/images/1-56aa56f01a444996deb8e3c4b474eb88.png"},6567:(e,s,a)=>{a.r(s),a.d(s,{assets:()=>c,contentTitle:()=>o,default:()=>l,frontMatter:()=>r,metadata:()=>n,toc:()=>d});const n=JSON.parse('{"id":"HH-101/NVIDIA Isaac ROS Course/Isaac-ROS-DNN-Stereoscopic-Depth","title":"Isaac ROS DNN stereoscopic depth","description":"Isaac ROS DNN Stereo Depth official website link\uff1ahttps://nvidia-isaac-ros.github.io/repositoriesandpackages/isaacrosdnnstereodepth/index.html","source":"@site/docs/hh101/HH-101/13 - NVIDIA Isaac ROS Course/03-Isaac-ROS-DNN-Stereoscopic-Depth.md","sourceDirName":"HH-101/13 - NVIDIA Isaac ROS Course","slug":"/HH-101/NVIDIA Isaac ROS Course/Isaac-ROS-DNN-Stereoscopic-Depth","permalink":"/hh-101/HH-101/NVIDIA Isaac ROS Course/Isaac-ROS-DNN-Stereoscopic-Depth","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"title":"Isaac ROS DNN stereoscopic depth","sidebar_position":3},"sidebar":"hh101Sidebar","previous":{"title":"Isaac ROS Deep segmentation","permalink":"/hh-101/HH-101/NVIDIA Isaac ROS Course/Isaac-ROS-Deep-Segmentation"},"next":{"title":"Isaac ROS Free space segmentation","permalink":"/hh-101/HH-101/NVIDIA Isaac ROS Course/Isaac-ROS-Free-Space-Segmentation"}}');var t=a(74848),i=a(28453);const r={title:"Isaac ROS DNN stereoscopic depth",sidebar_position:3},o="Isaac ROS DNN stereoscopic depth",c={},d=[{value:"Overview",id:"overview",level:2},{value:"Quick Experience",id:"quick-experience",level:2}];function h(e){const s={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",img:"img",p:"p",pre:"pre",strong:"strong",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(s.header,{children:(0,t.jsx)(s.h1,{id:"isaac-ros-dnn-stereoscopic-depth",children:"Isaac ROS DNN stereoscopic depth"})}),"\n",(0,t.jsxs)(s.p,{children:["Isaac ROS DNN Stereo Depth official website link\uff1a",(0,t.jsx)(s.a,{href:"https://nvidia-isaac-ros.github.io/repositories_and_packages/isaac_ros_dnn_stereo_depth/index.html",children:"https://nvidia-isaac-ros.github.io/repositories_and_packages/isaac_ros_dnn_stereo_depth/index.html"})]}),"\n",(0,t.jsx)(s.h2,{id:"overview",children:"Overview"}),"\n",(0,t.jsx)(s.p,{children:"The vision depth perception problem is generally useful in many fields of robotics such as estimating the pose of a robotic arm in an object manipulation task, estimating distance of static or moving targets in autonomous robot navigation, tracking targets in delivery robots and so on. Isaac ROS DNN Stereo Depth is targeted at two Isaac applications, Isaac Manipulator and Isaac Perceptor. In Isaac Manipulator application, ESS is deployed in Isaac ROS cuMotion package as a plug-in node to provide depth perception maps for robot arm motion planning and control. In this scenario, multi-camera stereo streams of industrial robot arms on a table task are passed to ESS to obtain corresponding depth streams. The depth streams are used to segment the relative distance of robot arms from corresponding objects on the table; thus providing signals for collision avoidance and fine-grain control. Similarly, the Isaac Perceptor application uses several Isaac ROS packages, namely, Isaac ROS Nova, Isaac ROS Visual Slam, Isaac ROS Stereo Depth (ESS), Isaac ROS Nvblox and Isaac ROS Image Pipeline."}),"\n",(0,t.jsx)(s.p,{children:(0,t.jsx)(s.img,{alt:"image",src:a(6351).A+"",width:"1600",height:"300"})}),"\n",(0,t.jsx)(s.h2,{id:"quick-experience",children:"Quick Experience"}),"\n",(0,t.jsx)(s.p,{children:"To simplify development, we primarily use the Isaac ROS Dev Docker image and demonstrate the effects there. This demonstration does not require any camera device installation; it simulates the camera data stream by playing a rosbag file."}),"\n",(0,t.jsx)(s.p,{children:(0,t.jsx)(s.strong,{children:"Note: If you wish to install on your own device or connect a camera to develop other features, please refer to the Isaac ROS official website and connect to a designated NVIDIA camera model for custom development."})}),"\n",(0,t.jsx)(s.p,{children:"Open a terminal and enter the working directory"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{children:"cd ${ISAAC_ROS_WS}/src\n"})}),"\n",(0,t.jsx)(s.p,{children:"Enter the Isaac ROS Dev Docker container"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{children:"cd ${ISAAC_ROS_WS}/src/isaac_ros_common && \\\n./scripts/run_dev.sh\n"})}),"\n",(0,t.jsx)(s.p,{children:"Run the following startup command, where threshold:=0.0 can be changed to 0.4 at startup, which will have different effects."}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{children:"ros2 launch isaac_ros_examples isaac_ros_examples.launch.py launch_fragments:=ess_disparity \\\nengine_file_path:=${ISAAC_ROS_WS:?}/isaac_ros_assets/models/dnn_stereo_disparity/dnn_stereo_disparity_v4.1.0_onnx/ess.engine \\\nthreshold:=0.0\n"})}),"\n",(0,t.jsx)(s.p,{children:"Open a second terminal and enter the container"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{children:"cd ${ISAAC_ROS_WS}/src/isaac_ros_common && \\\n./scripts/run_dev.sh\n"})}),"\n",(0,t.jsx)(s.p,{children:"Run the following command"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{children:"ros2 bag play -l ${ISAAC_ROS_WS}/isaac_ros_assets/isaac_ros_ess/rosbags/ess_rosbag \\\n--remap /left/camera_info:=/left/camera_info_rect /right/camera_info:=/right/camera_info_rect\n"})}),"\n",(0,t.jsx)(s.p,{children:(0,t.jsx)(s.strong,{children:"View the results"})}),"\n",(0,t.jsx)(s.p,{children:"Open a third terminal and enter the container"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{children:"cd ${ISAAC_ROS_WS}/src/isaac_ros_common && \\\n./scripts/run_dev.sh\n"})}),"\n",(0,t.jsx)(s.p,{children:"Run the following command,"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{children:"ros2 run isaac_ros_ess isaac_ros_ess_visualizer.py\n"})}),"\n",(0,t.jsx)(s.p,{children:"When threshold is set to 0.0, the display results are as follows:"}),"\n",(0,t.jsx)(s.p,{children:(0,t.jsx)(s.img,{alt:"image",src:a(31860).A+"",width:"960",height:"576"})}),"\n",(0,t.jsx)(s.p,{children:"When the threshold is set to 0.4, the results are as follows:"}),"\n",(0,t.jsx)(s.p,{children:(0,t.jsx)(s.img,{alt:"image",src:a(64893).A+"",width:"960",height:"576"})})]})}function l(e={}){const{wrapper:s}={...(0,i.R)(),...e.components};return s?(0,t.jsx)(s,{...e,children:(0,t.jsx)(h,{...e})}):h(e)}},28453:(e,s,a)=>{a.d(s,{R:()=>r,x:()=>o});var n=a(96540);const t={},i=n.createContext(t);function r(e){const s=n.useContext(i);return n.useMemo(function(){return"function"==typeof e?e(s):{...s,...e}},[s,e])}function o(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),n.createElement(i.Provider,{value:s},e.children)}},31860:(e,s,a)=>{a.d(s,{A:()=>n});const n=a.p+"assets/images/2-216aa4cab5d478a34cf80a4a69bc56d5.png"},64893:(e,s,a)=>{a.d(s,{A:()=>n});const n=a.p+"assets/images/3-f6f28c57310995ba37ac4a454644066c.png"}}]);