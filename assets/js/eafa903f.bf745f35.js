"use strict";(globalThis.webpackChunkhemihex_docs=globalThis.webpackChunkhemihex_docs||[]).push([[4590],{28453:(e,n,r)=>{r.d(n,{R:()=>t,x:()=>i});var a=r(96540);const s={},l=a.createContext(s);function t(e){const n=a.useContext(l);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:t(e.components),a.createElement(l.Provider,{value:n},e.children)}},62490:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>o,contentTitle:()=>i,default:()=>h,frontMatter:()=>t,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"HH-101/Offline AI Model/multimodal-autonomous-proxy-application-11-offlineaimodel-11-25","title":"Multimodal Autonomous Proxy Application","description":"1. Concept Introduction","source":"@site/docs/hh101/HH-101/11 - Offline AI Model/26-multimodal-autonomous-proxy-application-11-offlineaimodel-11-25.md","sourceDirName":"HH-101/11 - Offline AI Model","slug":"/HH-101/Offline AI Model/multimodal-autonomous-proxy-application-11-offlineaimodel-11-25","permalink":"/hh-101/HH-101/Offline AI Model/multimodal-autonomous-proxy-application-11-offlineaimodel-11-25","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":0,"frontMatter":{"title":"Multimodal Autonomous Proxy Application","sidebar_position":0},"sidebar":"hh101Sidebar","previous":{"title":"Multimodal Table Scanning Application","permalink":"/hh-101/HH-101/Offline AI Model/multimodal-table-scanning-application-11-offlineaimodel-11-24"},"next":{"title":"Multimodal Visual Understanding Application","permalink":"/hh-101/HH-101/Offline AI Model/multimodal-visual-understanding-11-offlineaimodel-11-11"}}');var s=r(74848),l=r(28453);const t={title:"Multimodal Autonomous Proxy Application",sidebar_position:0},i="9.Multimodal autonomous proxy application",o={},c=[{value:"1. Concept Introduction",id:"1-concept-introduction",level:2},{value:"1.1 What is an &quot;Autonomous Agent&quot;?",id:"11-what-is-an-autonomous-agent",level:3},{value:"1.2 Implementation Principles",id:"12-implementation-principles",level:3},{value:"2. Code Analysis",id:"2-code-analysis",level:2},{value:"Key Code",id:"key-code",level:3},{value:"1. Agent Core Workflow ( largemodel/utils/ai_agent.py )",id:"1-agent-core-workflow--largemodelutilsai_agentpy-",level:4},{value:"2. Interacting with the LLM in Task Planning ( largemodel/utils/ai_agent.py )",id:"2-interacting-with-the-llm-in-task-planning--largemodelutilsai_agentpy-",level:4},{value:"3. Parameter processing and data flow implementation( largemodel/utils/ai_agent.py )",id:"3-parameter-processing-and-data-flow-implementation-largemodelutilsai_agentpy-",level:4},{value:"Code Analysis",id:"code-analysis",level:3},{value:"3. Practical Operations",id:"3-practical-operations",level:2},{value:"3.1 Configuring the Offline Large Model",id:"31-configuring-the-offline-large-model",level:3},{value:"3.1.1 Configuring the LLM Platform ( HemiHex.yaml )",id:"311-configuring-the-llm-platform--hemihexyaml-",level:4},{value:"3.1.2 Configuration model interface( large_model_interface.yaml )",id:"312-configuration-model-interface-large_model_interfaceyaml-",level:4},{value:"3.2 Starting and Testing the Function",id:"32-starting-and-testing-the-function",level:3}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",p:"p",pre:"pre",...(0,l.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"9multimodal-autonomous-proxy-application",children:"9.Multimodal autonomous proxy application"})}),"\n",(0,s.jsx)(n.h2,{id:"1-concept-introduction",children:"1. Concept Introduction"}),"\n",(0,s.jsx)(n.h3,{id:"11-what-is-an-autonomous-agent",children:'1.1 What is an "Autonomous Agent"?'}),"\n",(0,s.jsx)(n.p,{children:"In the largemodel project, multimodal autonomous agents represent the most advanced form of intelligence. Rather than simply responding to a user's command, they are capable of autonomously thinking, planning, and continuously invoking multiple tools to achieve a complex goal ."}),"\n",(0,s.jsx)(n.p,{children:"The core of this functionality is the **agent_call ** tool or its underlying **ToolChainManager . When a user issues a complex request that cannot be accomplished with a single tool call, the autonomous agent is activated."}),"\n",(0,s.jsx)(n.h3,{id:"12-implementation-principles",children:"1.2 Implementation Principles"}),"\n",(0,s.jsx)(n.p,{children:'The autonomous agent implementation in largemodel follows the industry-leading ReAct (Reason + Act) paradigm. Its core concept is to mimic the human problem-solving process, cycling between "thinking" and "acting."'}),"\n",(0,s.jsx)(n.p,{children:"This think -> act -> observe cycle continues until the initial goal is achieved, at which point the agent generates and outputs the final answer."}),"\n",(0,s.jsx)(n.h2,{id:"2-code-analysis",children:"2. Code Analysis"}),"\n",(0,s.jsx)(n.h3,{id:"key-code",children:"Key Code"}),"\n",(0,s.jsx)(n.h4,{id:"1-agent-core-workflow--largemodelutilsai_agentpy-",children:"1. Agent Core Workflow ( largemodel/utils/ai_agent.py )"}),"\n",(0,s.jsx)(n.p,{children:'The _execute_agent_workflow function is the agent\'s main execution loop, defining the core "plan -> execute" process.'}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'# From largemodel/utils/ai_agent.py\r\n\u200b\r\nclass\r\nAIAgent\r\n:\r\n# ...\r\n\u200b\r\ndef\r\n_execute_agent_workflow\r\n(\r\nself\r\n,\r\ntask_description\r\n:\r\nstr\r\n)\r\n->\r\nDict\r\n[\r\nstr\r\n,\r\nAny\r\n]:\r\n"""\r\nExecutes the agent workflow: Plan -> Execute. / \u6267\u884cAgent\u5de5\u4f5c\u6d41\uff1a\u89c4\u5212 -> \u6267\u884c\u3002\r\n"""\r\ntry\r\n:\r\n# Step 1: Mission Planning\r\nself\r\n.\r\nnode\r\n.\r\nget_logger\r\n().\r\ninfo\r\n(\r\n"AI Agent starting task planning phase"\r\n)\r\nplan_result\r\n=\r\nself\r\n.\r\n_plan_task\r\n(\r\ntask_description\r\n)\r\n# ... (Return early if planning fails)\r\n\u200b\r\nself\r\n.\r\ntask_steps\r\n=\r\nplan_result\r\n[\r\n"steps"\r\n]\r\n\u200b\r\n# Step 2: Follow all steps in order\r\nexecution_results\r\n= []\r\ntool_outputs\r\n= []\r\n\u200b\r\nfor\r\ni\r\n,\r\nstep\r\nin\r\nenumerate\r\n(\r\nself\r\n.\r\ntask_steps\r\n):\r\n# 2.1. Processing data references in parameters before execution\r\nprocessed_parameters\r\n=\r\nself\r\n.\r\n_process_step_parameters\r\n(\r\nstep\r\n.\r\nget\r\n(\r\n"parameters"\r\n, {}),\r\ntool_outputs\r\n)\r\nstep\r\n[\r\n"parameters"\r\n] =\r\nprocessed_parameters\r\n\u200b\r\n# 2.2. Execute a single step\r\nstep_result\r\n=\r\nself\r\n.\r\n_execute_step\r\n(\r\nstep\r\n,\r\ntool_outputs\r\n)\r\nexecution_results\r\n.\r\nappend\r\n(\r\nstep_result\r\n)\r\n\u200b\r\n# 2.3. If the step succeeds, save its output for reference in subsequent steps\r\nif\r\nstep_result\r\n.\r\nget\r\n(\r\n"success"\r\n)\r\nand\r\nstep_result\r\n.\r\nget\r\n(\r\n"tool_output"\r\n):\r\ntool_outputs\r\n.\r\nappend\r\n(\r\nstep_result\r\n[\r\n"tool_output"\r\n])\r\nelse\r\n:\r\n# If any step fails, abort the entire task\r\nreturn\r\n{\r\n"success"\r\n:\r\nFalse\r\n,\r\n"message"\r\n:\r\nf"Task terminated because step \'{step[\'description\']}\' failed."\r\n}\r\n# ... Summarize and return the final result\r\nsummary\r\n=\r\nself\r\n.\r\n_summarize_execution\r\n(\r\ntask_description\r\n,\r\nexecution_results\r\n)\r\nreturn\r\n{\r\n"success"\r\n:\r\nTrue\r\n,\r\n"message"\r\n:\r\nsummary\r\n,\r\n"results"\r\n:\r\nexecution_results\r\n}\r\n\u200b\r\n# ... (Exception handling)\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# From largemodel/utils/ai_agent.py\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"class\r\nAIAgent\r\n:\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# ...\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"def\r\n_execute_agent_workflow\r\n(\r\nself\r\n,\r\ntask_description\r\n:\r\nstr\r\n)\r\n->\r\nDict\r\n[\r\nstr\r\n,\r\nAny\r\n]:\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'"""\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"Executes the agent workflow: Plan -> Execute. / \u6267\u884cAgent\u5de5\u4f5c\u6d41\uff1a\u89c4\u5212 -> \u6267\u884c\u3002\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'"""\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"try\r\n:\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Step 1: Mission Planning\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'self\r\n.\r\nnode\r\n.\r\nget_logger\r\n().\r\ninfo\r\n(\r\n"AI Agent starting task planning phase"\r\n)\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"plan_result\r\n=\r\nself\r\n.\r\n_plan_task\r\n(\r\ntask_description\r\n)\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# ... (Return early if planning fails)\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'self\r\n.\r\ntask_steps\r\n=\r\nplan_result\r\n[\r\n"steps"\r\n]\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Step 2: Follow all steps in order\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"execution_results\r\n= []\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"tool_outputs\r\n= []\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"for\r\ni\r\n,\r\nstep\r\nin\r\nenumerate\r\n(\r\nself\r\n.\r\ntask_steps\r\n):\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# 2.1. Processing data references in parameters before execution\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'processed_parameters\r\n=\r\nself\r\n.\r\n_process_step_parameters\r\n(\r\nstep\r\n.\r\nget\r\n(\r\n"parameters"\r\n, {}),\r\ntool_outputs\r\n)\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'step\r\n[\r\n"parameters"\r\n] =\r\nprocessed_parameters\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# 2.2. Execute a single step\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"step_result\r\n=\r\nself\r\n.\r\n_execute_step\r\n(\r\nstep\r\n,\r\ntool_outputs\r\n)\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"execution_results\r\n.\r\nappend\r\n(\r\nstep_result\r\n)\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# 2.3. If the step succeeds, save its output for reference in subsequent steps\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'if\r\nstep_result\r\n.\r\nget\r\n(\r\n"success"\r\n)\r\nand\r\nstep_result\r\n.\r\nget\r\n(\r\n"tool_output"\r\n):\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'tool_outputs\r\n.\r\nappend\r\n(\r\nstep_result\r\n[\r\n"tool_output"\r\n])\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"else\r\n:\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# If any step fails, abort the entire task\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'return\r\n{\r\n"success"\r\n:\r\nFalse\r\n,\r\n"message"\r\n:\r\nf"Task terminated because step \'{step[\'description\']}\' failed."\r\n}\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# ... Summarize and return the final result\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"summary\r\n=\r\nself\r\n.\r\n_summarize_execution\r\n(\r\ntask_description\r\n,\r\nexecution_results\r\n)\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'return\r\n{\r\n"success"\r\n:\r\nTrue\r\n,\r\n"message"\r\n:\r\nsummary\r\n,\r\n"results"\r\n:\r\nexecution_results\r\n}\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# ... (Exception handling)\n"})}),"\n",(0,s.jsx)(n.h4,{id:"2-interacting-with-the-llm-in-task-planning--largemodelutilsai_agentpy-",children:"2. Interacting with the LLM in Task Planning ( largemodel/utils/ai_agent.py )"}),"\n",(0,s.jsx)(n.p,{children:"The core of the _plan_task function is to build a sophisticated prompt, leveraging the large model's inherent reasoning capabilities to generate a structured execution plan."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'# From largemodel/utils/ai_agent.py\r\n\u200b\r\nclass\r\nAIAgent\r\n:\r\n# ...\r\ndef\r\n_plan_task\r\n(\r\nself\r\n,\r\ntask_description\r\n:\r\nstr\r\n)\r\n->\r\nDict\r\n[\r\nstr\r\n,\r\nAny\r\n]:\r\n"""\r\nUses the large model for task planning and decomposition. / \u4f7f\u7528\u5927\u6a21\u578b\u8fdb\u884c\u4efb\u52a1\u89c4\u5212\u548c\u5206\u89e3\u3002\r\n"""\r\n# Dynamically generate a list of available tools and their descriptions\r\ntool_descriptions\r\n= []\r\nfor\r\nname\r\n,\r\nadapter\r\nin\r\nself\r\n.\r\ntools_manager\r\n.\r\ntool_chain_manager\r\n.\r\ntools\r\n.\r\nitems\r\n():\r\n# ... (Get tool description from adapter.input_schema)\r\ntool_descriptions\r\n.\r\nappend\r\n(\r\nf"- {name}({params}): {description}"\r\n)\r\navailable_tools_str\r\n=\r\n"\\\\n"\r\n.\r\njoin\r\n(\r\ntool_descriptions\r\n)\r\n\u200b\r\n# Build a highly structured plan\r\nplanning_prompt\r\n=\r\nf"""\r\n\u4f5c\u4e3a\u4e00\u4e2a\u4e13\u4e1a\u7684\u4efb\u52a1\u89c4\u5212Agent\uff0c\u8bf7\u5c06\u7528\u6237\u4efb\u52a1\u5206\u89e3\u4e3a\u4e00\u7cfb\u5217\u5177\u4f53\u7684\u3001\u53ef\u6267\u884c\u7684JSON\u6b65\u9aa4\u3002\r\n\u200b\r\n**# Available Tools:**\r\n{available_tools_str}\r\n\u200b\r\n**# Core Rules:**\r\n1.  **Data Passing**: When a subsequent step needs to use the output of a previous step, you **must** use the `{{{{steps.N.outputs.KEY}}}}` format for referencing.\r\n- `N` is the step ID (starting from 1).\r\n- `KEY` is the specific field name in the output data of the previous step.\r\n- `outputs` can be followed by `data` (for primary data) or `metadata.sub_key` (for metadata).\r\n2.  **JSON Format**: You must strictly return a JSON object. Do not include any Markdown wrappers (like ```json```).\r\n3.  **Tool Selection**: Strictly select the most appropriate tool based on its description.\r\n\u200b\r\n**# User Task:**\r\n{task_description}\r\n"""\r\n# Calling large models for planning\r\nmessages_to_use\r\n= [{\r\n"role"\r\n:\r\n"user"\r\n,\r\n"content"\r\n:\r\nplanning_prompt\r\n}]\r\n# Note that the general text reasoning interface is called here\r\nresult\r\n=\r\nself\r\n.\r\nnode\r\n.\r\nmodel_client\r\n.\r\ninfer_with_text\r\n(\r\n""\r\n,\r\nmessage\r\n=\r\nmessages_to_use\r\n)\r\n# ... (Parse the JSON response and return a list of steps)\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# From largemodel/utils/ai_agent.py\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"class\r\nAIAgent\r\n:\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# ...\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"def\r\n_plan_task\r\n(\r\nself\r\n,\r\ntask_description\r\n:\r\nstr\r\n)\r\n->\r\nDict\r\n[\r\nstr\r\n,\r\nAny\r\n]:\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'"""\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"Uses the large model for task planning and decomposition. / \u4f7f\u7528\u5927\u6a21\u578b\u8fdb\u884c\u4efb\u52a1\u89c4\u5212\u548c\u5206\u89e3\u3002\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'"""\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Dynamically generate a list of available tools and their descriptions\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"tool_descriptions\r\n= []\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"for\r\nname\r\n,\r\nadapter\r\nin\r\nself\r\n.\r\ntools_manager\r\n.\r\ntool_chain_manager\r\n.\r\ntools\r\n.\r\nitems\r\n():\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# ... (Get tool description from adapter.input_schema)\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'tool_descriptions\r\n.\r\nappend\r\n(\r\nf"- {name}({params}): {description}"\r\n)\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'available_tools_str\r\n=\r\n"\\\\n"\r\n.\r\njoin\r\n(\r\ntool_descriptions\r\n)\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Build a highly structured plan\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'planning_prompt\r\n=\r\nf"""\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"\u4f5c\u4e3a\u4e00\u4e2a\u4e13\u4e1a\u7684\u4efb\u52a1\u89c4\u5212Agent\uff0c\u8bf7\u5c06\u7528\u6237\u4efb\u52a1\u5206\u89e3\u4e3a\u4e00\u7cfb\u5217\u5177\u4f53\u7684\u3001\u53ef\u6267\u884c\u7684JSON\u6b65\u9aa4\u3002\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"**# Available Tools:**\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"{available_tools_str}\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"**# Core Rules:**\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"1.  **Data Passing**: When a subsequent step needs to use the output of a previous step, you **must** use the `{{{{steps.N.outputs.KEY}}}}` format for referencing.\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"- `N` is the step ID (starting from 1).\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"- `KEY` is the specific field name in the output data of the previous step.\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"- `outputs` can be followed by `data` (for primary data) or `metadata.sub_key` (for metadata).\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"2.  **JSON Format**: You must strictly return a JSON object. Do not include any Markdown wrappers (like ```json```).\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"3.  **Tool Selection**: Strictly select the most appropriate tool based on its description.\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"**# User Task:**\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"{task_description}\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'"""\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Calling large models for planning\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'messages_to_use\r\n= [{\r\n"role"\r\n:\r\n"user"\r\n,\r\n"content"\r\n:\r\nplanning_prompt\r\n}]\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Note that the general text reasoning interface is called here\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'result\r\n=\r\nself\r\n.\r\nnode\r\n.\r\nmodel_client\r\n.\r\ninfer_with_text\r\n(\r\n""\r\n,\r\nmessage\r\n=\r\nmessages_to_use\r\n)\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# ... (Parse the JSON response and return a list of steps)\n"})}),"\n",(0,s.jsx)(n.h4,{id:"3-parameter-processing-and-data-flow-implementation-largemodelutilsai_agentpy-",children:"3. Parameter processing and data flow implementation( largemodel/utils/ai_agent.py )"}),"\n",(0,s.jsx)(n.p,{children:"The _process_step_parameters function is responsible for parsing placeholders and implementing data flow between steps."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'# From largemodel/utils/ai_agent.py\r\n\u200b\r\nclass\r\nAIAgent\r\n:\r\n# ...\r\ndef\r\n_process_step_parameters\r\n(\r\nself\r\n,\r\nparameters\r\n:\r\nDict\r\n[\r\nstr\r\n,\r\nAny\r\n],\r\nprevious_outputs\r\n:\r\nList\r\n[\r\nAny\r\n])\r\n->\r\nDict\r\n[\r\nstr\r\n,\r\nAny\r\n]:\r\n"""\r\nParses parameter dictionary, finds and replaces all {{...}} references.\r\n"""\r\nprocessed_params\r\n=\r\nparameters\r\n.\r\ncopy\r\n()\r\n# Regular expression used to match placeholders in the format {{steps.N.outputs.KEY}}\r\npattern\r\n=\r\nre\r\n.\r\ncompile\r\n(\r\nr"\\\\{\\\\{steps\\\\.(\\\\d+)\\\\.outputs\\\\.(.+?)\\\\}\\\\}"\r\n)\r\n\u200b\r\nfor\r\nkey\r\n,\r\nvalue\r\nin\r\nprocessed_params\r\n.\r\nitems\r\n():\r\nif\r\nisinstance\r\n(\r\nvalue\r\n,\r\nstr\r\n)\r\nand\r\npattern\r\n.\r\nsearch\r\n(\r\nvalue\r\n):\r\n# Use re.sub and a replacement function to process all found placeholders\r\n#The replacement function looks up and returns a value from the previous_outputs list.\r\nprocessed_params\r\n[\r\nkey\r\n] =\r\npattern\r\n.\r\nsub\r\n(\r\nreplacer_function\r\n,\r\nvalue\r\n)\r\nreturn\r\nprocessed_params\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# From largemodel/utils/ai_agent.py\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"class\r\nAIAgent\r\n:\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# ...\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"def\r\n_process_step_parameters\r\n(\r\nself\r\n,\r\nparameters\r\n:\r\nDict\r\n[\r\nstr\r\n,\r\nAny\r\n],\r\nprevious_outputs\r\n:\r\nList\r\n[\r\nAny\r\n])\r\n->\r\nDict\r\n[\r\nstr\r\n,\r\nAny\r\n]:\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'"""\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"Parses parameter dictionary, finds and replaces all {{...}} references.\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'"""\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"processed_params\r\n=\r\nparameters\r\n.\r\ncopy\r\n()\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Regular expression used to match placeholders in the format {{steps.N.outputs.KEY}}\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'pattern\r\n=\r\nre\r\n.\r\ncompile\r\n(\r\nr"\\\\{\\\\{steps\\\\.(\\\\d+)\\\\.outputs\\\\.(.+?)\\\\}\\\\}"\r\n)\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"for\r\nkey\r\n,\r\nvalue\r\nin\r\nprocessed_params\r\n.\r\nitems\r\n():\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"if\r\nisinstance\r\n(\r\nvalue\r\n,\r\nstr\r\n)\r\nand\r\npattern\r\n.\r\nsearch\r\n(\r\nvalue\r\n):\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Use re.sub and a replacement function to process all found placeholders\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"#The replacement function looks up and returns a value from the previous_outputs list.\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"processed_params\r\n[\r\nkey\r\n] =\r\npattern\r\n.\r\nsub\r\n(\r\nreplacer_function\r\n,\r\nvalue\r\n)\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"return\r\nprocessed_params\n"})}),"\n",(0,s.jsx)(n.h3,{id:"code-analysis",children:"Code Analysis"}),"\n",(0,s.jsx)(n.p,{children:'The AI \u200b\u200bAgent is the "brain" of the system, translating high-level, sometimes ambiguous, tasks posed by the user into a precise, ordered series of tool calls. Its implementation is independent of any specific model platform and built on a general, extensible architecture.'}),"\n",(0,s.jsx)(n.p,{children:"Dynamic Task Planning : The Agent's core capability lies in the _plan_task function. Rather than relying on hard-coded logic, it dynamically generates task plans by interacting with a larger model."}),"\n",(0,s.jsx)(n.p,{children:'Toolchain and Data Flow : Real-world tasks often require the collaboration of multiple tools. For example, "take a picture and describe" requires the output (image path) of the "take a picture" tool to be used as the input of the "describe" tool. The AI \u200b\u200bAgent elegantly implements this through the _process_step_parameters function.'}),"\n",(0,s.jsx)(n.p,{children:"Supervised Execution and Fault Tolerance : _execute_agent_workflow constitutes the Agent's main execution loop. It strictly follows the planned sequence of steps, executing each action sequentially and ensuring data is correctly passed between them."}),"\n",(0,s.jsx)(n.p,{children:"In summary, the general implementation of the AI \u200b\u200bAgent demonstrates an advanced software architecture: rather than solving a problem directly, it builds a framework that enables an external, general-purpose reasoning engine (a large model) to solve the problem. Through two core mechanisms, dynamic programming and data flow management, the Agent orchestrates a series of independent tools into complex workflows capable of completing advanced tasks."}),"\n",(0,s.jsx)(n.h2,{id:"3-practical-operations",children:"3. Practical Operations"}),"\n",(0,s.jsx)(n.h3,{id:"31-configuring-the-offline-large-model",children:"3.1 Configuring the Offline Large Model"}),"\n",(0,s.jsx)(n.h4,{id:"311-configuring-the-llm-platform--hemihexyaml-",children:"3.1.1 Configuring the LLM Platform ( HemiHex.yaml )"}),"\n",(0,s.jsx)(n.p,{children:"This file determines which large model platform the model_service node loads as its primary language model."}),"\n",(0,s.jsx)(n.p,{children:"Open the file in the terminal :"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"vim\r\n~/yahboom_ws/src/largemodel/config/HemiHex.yaml\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"vim\r\n~/yahboom_ws/src/largemodel/config/HemiHex.yaml\n"})}),"\n",(0,s.jsx)(n.p,{children:"Modify/Confirm llm_platform :"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"model_service\r\n:\r\n#Model server node parameters\r\nros__parameters\r\n:\r\nlanguage\r\n:\r\n'zh'\r\n#Large Model Interface Language\r\nuseolinetts\r\n:\r\nTrue\r\n#This item is invalid in text mode and can be ignored\r\n\u200b\r\n# Large model configuration\r\nllm_platform\r\n:\r\n'ollama'\r\n#Key: Make sure it's 'ollama'\r\nregional_setting\r\n:\r\n\"China\"\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"model_service\r\n:\r\n#Model server node parameters\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"ros__parameters\r\n:\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"language\r\n:\r\n'zh'\r\n#Large Model Interface Language\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"useolinetts\r\n:\r\nTrue\r\n#This item is invalid in text mode and can be ignored\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"\u200b\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Large model configuration\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"llm_platform\r\n:\r\n'ollama'\r\n#Key: Make sure it's 'ollama'\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'regional_setting\r\n:\r\n"China"\n'})}),"\n",(0,s.jsx)(n.h4,{id:"312-configuration-model-interface-large_model_interfaceyaml-",children:"3.1.2 Configuration model interface( large_model_interface.yaml )"}),"\n",(0,s.jsx)(n.p,{children:"This file defines which visual model to use when the platform is selected as ollama ."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"\r\nvim ~/yahboom_ws/src/largemodel/config/large_model_interface.yaml\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"vim ~/yahboom_ws/src/largemodel/config/large_model_interface.yaml\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'#.....\r\n## \u79bb\u7ebf\u5927\u6a21\u578b (Offline Large Language Models)\r\n# Ollama Configuration\r\nollama_host:\r\n"http://localhost:11434"\r\n# Ollama server address\r\nollama_model:\r\n"llava"\r\n# Key: Change this to the multimodal model you downloaded, such as "llava"\r\n#.....\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"#.....\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"## \u79bb\u7ebf\u5927\u6a21\u578b (Offline Large Language Models)\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Ollama Configuration\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'ollama_host:\r\n"http://localhost:11434"\r\n# Ollama server address\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'ollama_model:\r\n"llava"\r\n# Key: Change this to the multimodal model you downloaded, such as "llava"\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"#.....\n"})}),"\n",(0,s.jsx)(n.p,{children:"Note : Please make sure that the model specified in the configuration parameters (such as llava ) can handle multimodal input."}),"\n",(0,s.jsx)(n.h3,{id:"32-starting-and-testing-the-function",children:"3.2 Starting and Testing the Function"}),"\n",(0,s.jsx)(n.p,{children:"Note: Due to performance limitations, this example cannot be run on the Jetson Orin Nano 4GB. To experience this function, please refer to the corresponding section in [Online Large Model (Voice Interaction)]"}),"\n",(0,s.jsx)(n.p,{children:"Start the largemodel main program : Open a terminal and run the following command:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"\r\nros2 launch largemodel largemodel_control.launch.py\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"ros2 launch largemodel largemodel_control.launch.py\n"})}),"\n",(0,s.jsx)(n.p,{children:"After successful initialization, say the wake-up word and begin asking questions based on the current environment. Save the generated description of the environment as a text document."}),"\n",(0,s.jsx)(n.p,{children:"Observe the results : In the first terminal running the main program, you will see log output indicating that the system receives the text command, invokes the aiagent tool, and then provides a prompt to the LLM. The LLM will analyze the detailed tool invocation steps. For example, the current question will invoke the seewhat tool to capture the image, which will then be parsed by the LLM. The parsed text will be saved in the ~/yahboom_ws/src/largemodel/resources_file/documents folder."})]})}function h(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}}}]);