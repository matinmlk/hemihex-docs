"use strict";(globalThis.webpackChunkhemihex_docs=globalThis.webpackChunkhemihex_docs||[]).push([[8050],{28453:(e,n,s)=>{s.d(n,{R:()=>r,x:()=>a});var o=s(96540);const i={},t=o.createContext(i);function r(e){const n=o.useContext(t);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),o.createElement(t.Provider,{value:n},e.children)}},92024:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>m,frontMatter:()=>r,metadata:()=>o,toc:()=>d});const o=JSON.parse('{"id":"Jetson/Advanced Vision/YOLO11/pose-estimation-on-jetson","title":"Pose Estimation on Jetson (YOLO)","description":"This section demonstrates human pose estimation on NVIDIA Jetson","source":"@site/docs/Jetson/07 - Advanced Vision/3-YOLO11/10-pose-estimation-on-jetson.md","sourceDirName":"Jetson/07 - Advanced Vision/3-YOLO11","slug":"/Jetson/Advanced Vision/YOLO11/pose-estimation-on-jetson","permalink":"/docs/Jetson/Advanced Vision/YOLO11/pose-estimation-on-jetson","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/Jetson/07 - Advanced Vision/3-YOLO11/10-pose-estimation-on-jetson.md","tags":[],"version":"current","sidebarPosition":10,"frontMatter":{"sidebar_position":10,"title":"Pose Estimation on Jetson (YOLO)"},"sidebar":"tutorialSidebar","previous":{"title":"Instance Segmentation on Jetson (YOLO)","permalink":"/docs/Jetson/Advanced Vision/YOLO11/instance-segmentation-on-jetson"},"next":{"title":"Image Classification on Jetson (YOLO)","permalink":"/docs/Jetson/Advanced Vision/YOLO11/image-classification-on-jetson"}}');var i=s(74848),t=s(28453);const r={sidebar_position:10,title:"Pose Estimation on Jetson (YOLO)"},a="Pose Estimation on Jetson",l={},d=[{value:"1. Enable Optimal Jetson Performance",id:"1-enable-optimal-jetson-performance",level:2},{value:"Enable MAX Power Mode",id:"enable-max-power-mode",level:3},{value:"Enable Jetson Clocks",id:"enable-jetson-clocks",level:3},{value:"2. Pose Estimation on Images",id:"2-pose-estimation-on-images",level:2},{value:"Enter Demo Directory",id:"enter-demo-directory",level:3},{value:"Run Image Pose Estimation",id:"run-image-pose-estimation",level:3},{value:"Sample Code (Image Pose Estimation)",id:"sample-code-image-pose-estimation",level:3},{value:"3. Pose Estimation on Video",id:"3-pose-estimation-on-video",level:2},{value:"Run Video Pose Estimation",id:"run-video-pose-estimation",level:3},{value:"Sample Code (Video Pose Estimation)",id:"sample-code-video-pose-estimation",level:3},{value:"4. Real-Time Pose Estimation",id:"4-real-time-pose-estimation",level:2},{value:"5. Notes",id:"5-notes",level:2}];function c(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"pose-estimation-on-jetson",children:"Pose Estimation on Jetson"})}),"\n",(0,i.jsxs)(n.p,{children:["This section demonstrates ",(0,i.jsx)(n.strong,{children:"human pose estimation"})," on NVIDIA Jetson\r\nusing ",(0,i.jsx)(n.strong,{children:"Ultralytics YOLO Pose models"}),". Examples include ",(0,i.jsx)(n.strong,{children:"image"}),",\r\n",(0,i.jsx)(n.strong,{children:"video"}),", and ",(0,i.jsx)(n.strong,{children:"real-time camera"})," inference."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"1-enable-optimal-jetson-performance",children:"1. Enable Optimal Jetson Performance"}),"\n",(0,i.jsx)(n.p,{children:"Before running pose estimation, ensure Jetson is running at maximum\r\nperformance."}),"\n",(0,i.jsx)(n.h3,{id:"enable-max-power-mode",children:"Enable MAX Power Mode"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"sudo nvpmodel -m 2\n"})}),"\n",(0,i.jsx)(n.h3,{id:"enable-jetson-clocks",children:"Enable Jetson Clocks"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"sudo jetson_clocks\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"2-pose-estimation-on-images",children:"2. Pose Estimation on Images"}),"\n",(0,i.jsx)(n.h3,{id:"enter-demo-directory",children:"Enter Demo Directory"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"cd ~/ultralytics/ultralytics/yahboom_demo\n"})}),"\n",(0,i.jsx)(n.h3,{id:"run-image-pose-estimation",children:"Run Image Pose Estimation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"python3 03.pose_image.py\n"})}),"\n",(0,i.jsx)(n.p,{children:"Results are saved to:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"~/ultralytics/ultralytics/output/\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"sample-code-image-pose-estimation",children:"Sample Code (Image Pose Estimation)"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from ultralytics import YOLO\r\n\r\nmodel = YOLO("yolo11n-pose.pt")\r\nresults = model("assets/people.jpg")\r\n\r\nfor r in results:\r\n    r.show()\r\n    r.save(filename="output/people_pose_output.jpg")\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"3-pose-estimation-on-video",children:"3. Pose Estimation on Video"}),"\n",(0,i.jsx)(n.h3,{id:"run-video-pose-estimation",children:"Run Video Pose Estimation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"python3 03.pose_video.py\n"})}),"\n",(0,i.jsx)(n.p,{children:"Output video location:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"~/ultralytics/ultralytics/output/\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"sample-code-video-pose-estimation",children:"Sample Code (Video Pose Estimation)"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import cv2\r\nfrom ultralytics import YOLO\r\n\r\nmodel = YOLO("yolo11n-pose.pt")\r\ncap = cv2.VideoCapture("videos/people.mp4")\r\n\r\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\r\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\r\nfps = int(cap.get(cv2.CAP_PROP_FPS))\r\n\r\nout = cv2.VideoWriter(\r\n    "output/people_pose_output.mp4",\r\n    cv2.VideoWriter_fourcc(*"mp4v"),\r\n    fps,\r\n    (width, height)\r\n)\r\n\r\nwhile cap.isOpened():\r\n    ret, frame = cap.read()\r\n    if not ret:\r\n        break\r\n\r\n    results = model(frame)\r\n    annotated = results[0].plot()\r\n    out.write(annotated)\r\n\r\ncap.release()\r\nout.release()\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"4-real-time-pose-estimation",children:"4. Real-Time Pose Estimation"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"USB Camera"}),": OpenCV ",(0,i.jsx)(n.code,{children:"VideoCapture(0)"})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"CSI Camera"}),": GStreamer pipeline (",(0,i.jsx)(n.code,{children:"nvarguscamerasrc"}),")"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Real-time processing follows the same inference logic as video pose\r\nestimation."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"5-notes",children:"5. Notes"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Pose models output ",(0,i.jsx)(n.strong,{children:"keypoints"})," for each detected person"]}),"\n",(0,i.jsx)(n.li,{children:"Suitable for motion tracking and activity analysis"}),"\n",(0,i.jsxs)(n.li,{children:["Use ",(0,i.jsx)(n.strong,{children:"Nano pose models"})," for real-time inference"]}),"\n",(0,i.jsxs)(n.li,{children:["Export models to ",(0,i.jsx)(n.strong,{children:"TensorRT"})," for production deployment"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsxs)(n.p,{children:["Maintained by ",(0,i.jsx)(n.strong,{children:"HemiHex"})," for Jetson-based advanced vision workflows."]})]})}function m(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}}}]);