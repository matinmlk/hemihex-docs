"use strict";(globalThis.webpackChunkhemihex_docs=globalThis.webpackChunkhemihex_docs||[]).push([[1906],{16151:(e,n,a)=>{a.d(n,{A:()=>l});const l=a.p+"assets/images/image-20250627185035604-f330fb464644dc504d11a32ee6aa66d0.png"},25914:(e,n,a)=>{a.d(n,{A:()=>l});const l=a.p+"assets/images/1-72603c16534948b69dd6daeb2762a196.png"},28453:(e,n,a)=>{a.d(n,{R:()=>s,x:()=>r});var l=a(96540);const i={},t=l.createContext(i);function s(e){const n=l.useContext(t);return l.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),l.createElement(t.Provider,{value:n},e.children)}},55621:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>o,contentTitle:()=>r,default:()=>h,frontMatter:()=>s,metadata:()=>l,toc:()=>d});const l=JSON.parse('{"id":"HH-101/Offline AI Model/llama-3-2-11-offlineaimodel-11-3","title":"Llama 3.2","description":"Demo Environment","source":"@site/docs/hh101/HH-101/11 - Offline AI Model/03-llama-3-2-11-offlineaimodel-11-3.md","sourceDirName":"HH-101/11 - Offline AI Model","slug":"/HH-101/Offline AI Model/llama-3-2-11-offlineaimodel-11-3","permalink":"/hh-101/HH-101/Offline AI Model/llama-3-2-11-offlineaimodel-11-3","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":0,"frontMatter":{"title":"Llama 3.2","sidebar_position":0},"sidebar":"hh101Sidebar","previous":{"title":"Open WebUI","permalink":"/hh-101/HH-101/Offline AI Model/open-webui-11-offlineaimodel-11-2"},"next":{"title":"Qwen3","permalink":"/hh-101/HH-101/Offline AI Model/qwen3-11-offlineaimodel-11-4"}}');var i=a(74848),t=a(28453);const s={title:"Llama 3.2",sidebar_position:0},r="Llama 3.2",o={},d=[{value:"1. Model Size",id:"1-model-size",level:2},{value:"2. Performance",id:"2-performance",level:2},{value:"3. Using Llama 3.2",id:"3-using-llama-32",level:2},{value:"3.1 Running Llama 3.2",id:"31-running-llama-32",level:3},{value:"3.2 Starting a Conversation",id:"32-starting-a-conversation",level:3},{value:"3.3 Ending a Conversation",id:"33-ending-a-conversation",level:3},{value:"References",id:"references",level:2}];function c(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"llama-32",children:"Llama 3.2"})}),"\n",(0,i.jsx)(n.p,{children:"Demo Environment"}),"\n",(0,i.jsx)(n.p,{children:"Development Board : Jetson Orin series motherboard"}),"\n",(0,i.jsx)(n.admonition,{type:"warning",children:(0,i.jsx)(n.p,{children:"Due to performance limitations, the Jetson Orin Nano 4GB requires the reduced-parameter version"})}),"\n",(0,i.jsx)(n.p,{children:"Meta Llama 3.2 is a series of advanced open-source large-scale language models (LLMs) developed by the Meta AI department."}),"\n",(0,i.jsx)(n.h2,{id:"1-model-size",children:"1. Model Size"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Model"}),(0,i.jsx)(n.th,{children:"Size"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"llama3.2:1b"}),(0,i.jsx)(n.td,{children:"1.3GB"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"llama3.2:3b"}),(0,i.jsx)(n.td,{children:"2.0GB"})]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"2-performance",children:"2. Performance"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Llama 3.2 instruction-tuned benchmarks",src:a(77434).A+"",width:"3840",height:"3676"})}),"\n",(0,i.jsx)(n.h2,{id:"3-using-llama-32",children:"3. Using Llama 3.2"}),"\n",(0,i.jsx)(n.h3,{id:"31-running-llama-32",children:"3.1 Running Llama 3.2"}),"\n",(0,i.jsx)(n.p,{children:"Use the run command to run the model. If the model is not already downloaded, it will automatically pull the model from the Olama model library:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ollama run llama3.2:3b\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Screenshot",src:a(25914).A+"",width:"512",height:"214"})}),"\n",(0,i.jsx)(n.h3,{id:"32-starting-a-conversation",children:"3.2 Starting a Conversation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"How many minutes are there in a day?\n"})}),"\n",(0,i.jsx)(n.p,{children:"Response time depends on your hardware configuration, so please be patient!"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Screenshot",src:a(16151).A+"",width:"638",height:"126"})}),"\n",(0,i.jsx)(n.h3,{id:"33-ending-a-conversation",children:"3.3 Ending a Conversation"}),"\n",(0,i.jsx)(n.p,{children:"Use the Ctrl+d shortcut or /bye to end a conversation!"}),"\n",(0,i.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,i.jsx)(n.p,{children:"Ollama"}),"\n",(0,i.jsxs)(n.p,{children:["Official Website: ",(0,i.jsx)(n.a,{href:"https://ollama.com/",children:"https://ollama.com/"})]}),"\n",(0,i.jsxs)(n.p,{children:["GitHub: ",(0,i.jsx)(n.a,{href:"https://github.com/ollama/ollama",children:"https://github.com/ollama/ollama"})]}),"\n",(0,i.jsx)(n.p,{children:"Llama 3.2"}),"\n",(0,i.jsxs)(n.p,{children:["Official Website: ",(0,i.jsx)(n.a,{href:"https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_2/",children:"https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_2/"})]}),"\n",(0,i.jsxs)(n.p,{children:["Ollama Model: ",(0,i.jsx)(n.a,{href:"https://ollama.com/library/llama3.2",children:"https://ollama.com/library/llama3.2"})]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},77434:(e,n,a)=>{a.d(n,{A:()=>l});const l=a.p+"assets/images/c1a51716-d8bb-4642-8044-48f5022b777d-7c1ba523cf29ea8431e254cc016da07c.png"}}]);